{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0c45fc629d3d63ba39a4836cded2d932c1d505ff54a7cb002ca860f3d9bb67ee0",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "c45fc629d3d63ba39a4836cded2d932c1d505ff54a7cb002ca860f3d9bb67ee0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "This file is a compilation of all the codes to show the flow of our analysis process. However, they might not work as it was not tested to run due to the high computational time it requires. The output and run files are named as per analysis in the folder."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Importing Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "!pip install nltk\n",
    "!pip install text2emotion\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "#For Text Cleaning\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#For EDA\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#For text vectorizing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import random\n",
    "\n",
    "# Topic Modelling\n",
    "import gensim\n",
    "import pickle \n",
    "import os \n",
    "os.environ.update({'MALLET_HOME':r'C:/mallet-2.0.8/'})\n",
    "mallet_path = r'C:\\\\mallet-2.0.8\\\\bin\\\\mallet'\n",
    "\n",
    "# Emotion Analysis \n",
    "# import text2emotion as te\n",
    "\n",
    "# pos tagging \n",
    "from collections import Counter\n",
    "\n",
    "# ploting \n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# VADER generation \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# ER\n",
    "import sys\n",
    "import json\n",
    "import ast\n",
    "\n",
    "# Classification \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "from sklearn import model_selection, svm, feature_extraction, model_selection, manifold, preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import gensim.downloader as gensim_api\n",
    "## for deep learning\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Helper Functions\n",
    "## Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(review):\r\n",
    "    review = \" \".join([stemmer.stem(w.lower()) for w in word_tokenize(re.sub('[^a-zA-Z]+', ' ', review.replace(\"<br />\", \"\"))) if not w in stop_words])\r\n",
    "    return review\r\n",
    "    \r\n",
    "def preprocessG(review):\r\n",
    "    review = \" \".join([stemmer.stem(w.lower()) for w in word_tokenize(review) if not w in stop_words])\r\n",
    "    return review\r\n",
    "\r\n",
    "def getSmallerCorpus(news):\r\n",
    "    X = news.loc[:, news.columns != 'label']\r\n",
    "    y = news['label']\r\n",
    "    new_corpus, unwanted_data, new_corpus_y, unwanted_data_y = train_test_split(X,y,train_size= 0.45,  random_state=0, stratify=y)\r\n",
    "    new_corpus['label'] = new_corpus_y\r\n",
    "    return new_corpus\r\n"
   ]
  },
  {
   "source": [
    "## Topic Modelling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs2vecs(docs, dictionary):\n",
    "    # docs is a list of documents returned by corpus2docs.\n",
    "    # dictionary is a gensim.corpora.Dictionary object.\n",
    "    vecs1 = [dictionary.doc2bow(doc) for doc in docs]\n",
    "    return vecs1\n",
    "\n",
    "def save_model(classifier):\n",
    "    save_classifier = open(\"topicModel14.pickle\",\"wb\") #binary write\n",
    "    pickle.dump(classifier, save_classifier)\n",
    "    save_classifier.close()\n",
    "\n",
    "def format_topics_sentences(ldamodel, corpus, data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        # row = sorted(row, key=lambda x: (x[1]))\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        sent_topics_df = sent_topics_df.append(pd.Series([round(row[0][1],4),round(row[1][1],4),round(row[2][1],4),round(row[3][1],4),round(row[4][1],4),round(row[5][1],4),round(row[6][1],4),round(row[7][1],4),round(row[8][1],4),round(row[9][1],4),round(row[10][1],4),round(row[11][1],4),round(row[12][1],4),round(row[13][1],4)]), ignore_index=True)\n",
    "        print(i)\n",
    "\n",
    "    sent_topics_df.columns = ['Topic 0','Topic 1','Topic 2','Topic 3','Topic 4','Topic 5', 'Topic 6','Topic 7','Topic 8','Topic 9','Topic 10','Topic 11','Topic 12','Topic 13']\n",
    "       \n",
    "    # Add original text to the end of the output\n",
    "    data_sentence = [' '.join(w) for w in data]\n",
    "    contents = pd.Series(data_sentence)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "    "
   ]
  },
  {
   "source": [
    "## Name Entity Recognition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityDic(df):\n",
    "  entity_dic = {}\n",
    "  counter = 1\n",
    "  total_records = df.shape[0]\n",
    "  for index, row in df.iterrows():\n",
    "    text = row['text'] + \" \"+ row['title']\n",
    "    sys.stdout.write('\\rCompletion progress: ' + str(counter) + ' of ' + str(total_records) + \" articles\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    ## Put full stop behind each sentence\n",
    "    new = []\n",
    "    if \"\\n\" in text:\n",
    "        text = text.replace(\" \\n\", \". \")\n",
    "    text_list = text.split(\". \")\n",
    "    for x in text_list:\n",
    "        new.append(x + \".\")\n",
    "    \n",
    "    ## Cycle through each sentence\n",
    "    for x in new:\n",
    "        sent_tokens = word_tokenize(x)\n",
    "        tagged_sent = nltk.pos_tag(sent_tokens)\n",
    "        ne_tree = nltk.ne_chunk(tagged_sent)\n",
    "        ne_list = extract_ne_from_tree(ne_tree)\n",
    "        \n",
    "        ## Insert into dictionary\n",
    "        for y in ne_list:\n",
    "            if y[0] not in entity_dic:\n",
    "                entity_dic[y[0]] = {}\n",
    "            if y[0] in entity_dic:\n",
    "                string = y[1].lower()\n",
    "                if string not in entity_dic[y[0]]:\n",
    "                    entity_dic[y[0]][string] = 0\n",
    "                if string in entity_dic[y[0]]:\n",
    "                    entity_dic[y[0]][string] += 1\n",
    "    counter += 1\n",
    "  return entity_dic\n",
    "\n",
    "def extract_ne_from_tree ( tree ):\n",
    "    result = []\n",
    "    for s in tree.subtrees():\n",
    "        label = s.label()\n",
    "        if (label == 'PERSON' or label == 'ORGANIZATION' or label == 'GPE'):\n",
    "            leaves = s.leaves()\n",
    "            ne = ''\n",
    "            for l in leaves:\n",
    "                ne = ne + ' ' + l[0]\n",
    "            result.append((label, ne[1:]))\n",
    "    return result\n",
    "\n",
    "def addEntitiesToDataframe2(df):\n",
    "\n",
    "    entity_dic = {}\n",
    "    counter = 1\n",
    "    total_records = df.shape[0]\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        entity_dic['PERSON'] = {}\n",
    "        entity_dic['ORGANIZATION'] = {}\n",
    "        entity_dic['GPE'] = {}\n",
    "        text = row['text'] + \" \"+ row['title']\n",
    "        sys.stdout.write('\\rCompletion progress: ' + str(counter) + ' of ' + str(total_records) + \" articles\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        ## Put full stop behind each sentence\n",
    "        new = []\n",
    "        if \"\\n\" in text:\n",
    "          text = text.replace(\" \\n\", \". \")\n",
    "        text_list = text.split(\". \")\n",
    "        for x in text_list:\n",
    "            new.append(x + \".\")\n",
    "\n",
    "        ## Cycle through each sentence\n",
    "        for x in new:\n",
    "            sent_tokens = word_tokenize(x)\n",
    "            tagged_sent = nltk.pos_tag(sent_tokens)\n",
    "            ne_tree = nltk.ne_chunk(tagged_sent)\n",
    "            ne_list = extract_ne_from_tree(ne_tree)\n",
    "\n",
    "            ## Insert into dictionary\n",
    "            for y in ne_list:\n",
    "                if y[0] not in entity_dic:\n",
    "                    entity_dic[y[0]] = {}\n",
    "                if y[0] in entity_dic:\n",
    "                    string = y[1].lower()\n",
    "                    if string not in entity_dic[y[0]]:\n",
    "                        entity_dic[y[0]][string] = 0\n",
    "                    if string in entity_dic[y[0]]:\n",
    "                        entity_dic[y[0]][string] += 1\n",
    "        counter += 1\n",
    "\n",
    "        # Get df index\n",
    "        ind = index_list[i]\n",
    "\n",
    "        # get summation values\n",
    "        total_p = 0\n",
    "        for x in entity_dic['PERSON']:\n",
    "          total_p += entity_dic['PERSON'][x]\n",
    "\n",
    "        total_o = 0\n",
    "        for x in entity_dic['ORGANIZATION']:\n",
    "          total_o += entity_dic['ORGANIZATION'][x]\n",
    "\n",
    "        total_g = 0\n",
    "        for x in entity_dic['GPE']:\n",
    "          total_g += entity_dic['GPE'][x]\n",
    "        \n",
    "        # insert into DF\n",
    "        df.loc[ind:ind+1, 'person entities'] = str(entity_dic['PERSON'])\n",
    "        df.loc[ind:ind+1, 'organisation entities'] = str(entity_dic['ORGANIZATION'])\n",
    "        df.loc[ind:ind+1, 'location entities'] = str(entity_dic['GPE'])\n",
    "        df.loc[ind:ind+1, 'person entity count'] = total_p\n",
    "        df.loc[ind:ind+1, 'organisation entity count'] = total_o\n",
    "        df.loc[ind:ind+1, 'location entity count'] = total_g\n",
    "        entity_dic = {}\n",
    "        i+=1\n",
    "        \n",
    "    return df\n",
    "\n",
    "def attachTopEntities(df, fakeTop, realTop):\n",
    "    store = []\n",
    "    for x in trueTop:\n",
    "        for y in trueTop[x]:\n",
    "        store.append((\"(\" + str(x) + \")\" + y))\n",
    "\n",
    "    for x in fakeTop:\n",
    "        for y in fakeTop[x]:\n",
    "        item = (\"(\" + str(x) + \")\" + y)\n",
    "        if item not in store:\n",
    "            store.append(item)\n",
    "\n",
    "    for x in store:\n",
    "        df[x] = 0\n",
    "\n",
    "    return df, store\n",
    "\n",
    "def getTopEntityDic(entity_dic, n):\n",
    "    print()\n",
    "    bigstore = {}\n",
    "    top10entities = {}\n",
    "    for x in entity_dic:\n",
    "        first = str(x)[0] + \"_\"\n",
    "        bigstore[x] = []\n",
    "        print(x)\n",
    "        print(\"----------------\")\n",
    "        sorted_dic = sorted(entity_dic[x], key=entity_dic[x].get, reverse=True)\n",
    "        count = 0\n",
    "        for y in sorted_dic:\n",
    "        top10entities[y] = entity_dic[x][y]\n",
    "        print(y.ljust(40), \":\" + str(entity_dic[x][y]))\n",
    "        count += 1\n",
    "            if count == n:\n",
    "                break\n",
    "        top10 = dict(sorted(top10entities.items(), key=lambda item: item[1], reverse = True))\n",
    "        count = 0\n",
    "        result = []\n",
    "        for z in top10:\n",
    "        count += 1\n",
    "        result.append(str(z))\n",
    "            if count == n:\n",
    "                bigstore[x] = result \n",
    "                break\n",
    "        print()\n",
    "    return bigstore\n",
    "\n",
    "def getFinalEntityDF(finalEntitydf, store):\n",
    "    total_records = finalEntitydf.shape[0]\n",
    "    for index, row in finalEntitydf.iterrows():\n",
    "        sys.stdout.write('\\rCompletion progress: ' + str(index+1) + ' of ' + str(total_records) + \" articles\")\n",
    "        sys.stdout.flush()\n",
    "        # Person Entities\n",
    "        json_string = row['person entities']\n",
    "        dicp = ast.literal_eval(json_string)\n",
    "        for x in dicp:\n",
    "        item = \"(PERSON)\" + str(x)\n",
    "            if item in store:\n",
    "                finalEntitydf.loc[index, item] = dicp[x]\n",
    "\n",
    "        # Location Entities\n",
    "        json_string = row['location entities']\n",
    "        dicp = ast.literal_eval(json_string)\n",
    "        for x in dicp:\n",
    "        item = \"(GPE)\" + str(x)\n",
    "            if item in store:\n",
    "                finalEntitydf.loc[index, item] = dicp[x]\n",
    "            \n",
    "        # GPE Entities\n",
    "        json_string = row['organisation entities']\n",
    "        dicp = ast.literal_eval(json_string)\n",
    "        for x in dicp:\n",
    "        item = \"(ORGANISATION)\" + str(x)\n",
    "            if item in store:\n",
    "                finalEntitydf.loc[index, item] = dicp[x]\n",
    "    return finalEntitydf"
   ]
  },
  {
   "source": [
    "## POS tagging"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pos_tag_dist(df):\n",
    "    \n",
    "    \"\"\"Takes in a df : this dataframe contains the emotions,\n",
    "        and outputs the dataframe with additional pos tags above that have no more than 30% missing \"\"\"\n",
    "        \n",
    "    emotion_text = list(df['text'])\n",
    "    counts = []\n",
    "    for sentences in emotion_text:\n",
    "        tokens = nltk.word_tokenize(sentences)    \n",
    "        tags = nltk.pos_tag(tokens)\n",
    "        counts.append(Counter( tag for word,  tag in tags))\n",
    "\n",
    "    # creating the pos count feature and setting non rare pos tag features ,\n",
    "    df_post_dist = pd.DataFrame.from_records(counts)\n",
    "    df_post_dist_non_null = df_post_dist.loc[:,df_post_dist.columns[df_post_dist.isnull().mean() < 0.7]].reset_index()\n",
    "    df_post_dist_non_null.fillna(0,inplace=True)\n",
    "    \n",
    "    # combining the dataframe \n",
    "    return df_post_dist_non_null\n",
    "\n",
    "\n",
    "def group_pos_features(pos_tagged_df):\n",
    "\n",
    "    \"\"\"This function takes in the POS feature dataframe and group POS tags together.\n",
    "      Comments means that the POS tags in this data set is not prevelant as they either are not present or contain too much missing values\n",
    "\n",
    "      Unpresent POS tags  for now it is known to be insignificant as mentioned in the research paper :\n",
    "          pos_tagged_df['group_e'] = pos_tagged_df['EX']\n",
    "          pos_tagged_df['NR'] + pos_tagged_df['NPS']\n",
    "          pos_tagged_df['group_p'] = pos_tagged_df['PDT'] + pos_tagged_df['POS'] + pos_tagged_df['PP']\n",
    "          pos_tagged_df['group_t'] = pos_tagged_df['TO']\n",
    "          pos_tagged_df['group_u'] = pos_tagged_df['UH'] \n",
    "          pos_tagged_df['group_w'] = pos_tagged_df['WDT'] + pos_tagged_df['WP'] + pos_tagged_df['WP$'] + pos_tagged_df['WRB']\n",
    "          # Could be a future work to include using different POS tagging dictionaries\n",
    "     \"\"\" \n",
    "    #pos_group = ['group_c','group_d','group_f','group_i','group_j','group_m','group_n','group_r','group_v']\n",
    "    pos_list = ['CC','CD','DT','FW','IN','JJ','JJR','JJS','MD','NN', 'NNS', 'RBR','RB','VB','VBD', 'VBN','VBP','VBZ']\n",
    "    delete_pos_list = []\n",
    "    pos_dict = {}\n",
    "    for pos_l in pos_list:\n",
    "      \n",
    "      if pos_l in pos_tagged_df.columns:\n",
    "        pos_dict[pos_l] = np.array(list(pos_tagged_df[pos_l]))\n",
    "        delete_pos_list.append(pos_l)\n",
    "      else:\n",
    "        pos_dict[pos_l] = list(zerolistmaker(len(pos_tagged_df)))\n",
    "      \n",
    "    #print(np.sum([pos_dict['CC'],pos_dict['CD']] , axis=0))\n",
    "    pos_tagged_df['group_c'] = np.sum([pos_dict['CC'],pos_dict['CD']], axis=0) \n",
    "    pos_tagged_df['group_d'] = pos_dict['DT'] \n",
    "    pos_tagged_df['group_f'] = pos_dict['FW'] \n",
    "    pos_tagged_df['group_i'] = pos_dict['IN']\n",
    "    pos_tagged_df['group_j'] = np.sum([pos_dict['JJ'],pos_dict['JJR'], pos_dict['JJS']], axis=0)  \n",
    "    \n",
    "    pos_tagged_df['group_m'] = pos_dict['MD']\n",
    "    pos_tagged_df['group_n'] = np.sum([pos_dict['NN'],pos_dict['NNS']], axis=0) \n",
    "    \n",
    "    # changed RBP to RBR \n",
    "    pos_tagged_df['group_r'] = np.sum([pos_dict['RBR'],pos_dict['RB']], axis=0) \n",
    "    pos_tagged_df['group_v'] =  np.sum([pos_dict['VB'],pos_dict['VBD'], pos_dict['VBN'],  pos_dict['VBP'],  pos_dict['VBZ']], axis=0)  \n",
    "\n",
    "    return pos_tagged_df, delete_pos_list\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Emotions/Sentiment "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emotion\n",
    "def emotion_detection(sents):\n",
    "    \"\"\"Main algo for convertion for the 5 emotions \"\"\"\n",
    "    sent_emotion = te.get_emotion(sents)\n",
    "    return sent_emotion\n",
    "    \n",
    "\n",
    "# Generating the Emotions \n",
    "def generate_emotions(news_dup):\n",
    "    \n",
    "    \"\"\"Use to generate the dataframe that appends the orginal text and the emotion label vector\"\"\"\n",
    "    \n",
    "    emotion_list = []\n",
    "    for i, row in news_dup.iterrows():\n",
    "        emotion_dict = emotion_detection(row[2])\n",
    "        emotion_dict['text'] = row[2]\n",
    "        emotion_dict['label'] = row[3]\n",
    "        emotion_list.append(emotion_dict)\n",
    "        \n",
    "        \n",
    "    emotion_df = pd.DataFrame(emotion_list)\n",
    "    horizontal_stack = news_dup.merge(emotion_df, how='left', on='text')\n",
    "    horizontal_stack.drop(['index'], inplace=True, axis=1)       \n",
    "            \n",
    "    return horizontal_stack\n",
    "        \n",
    "# sentiment\n",
    "# generating Vader https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664\n",
    "def vader_score_generation(emo_pos_df):\n",
    "    \n",
    "    \"\"\"Generates the vader scores for the dataframe to create neu pos neg tags base on the text \"\"\"\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    polarity_Score = emo_pos_df['text'].apply(lambda review: sid.polarity_scores(review))\n",
    "    df_p_scores = polarity_Score.apply(pd.Series).reset_index() # generating the scores and appending it the dataframe end \n",
    "    emo_pos_dist_pscore =  emo_pos_df.merge(df_p_scores, left_on='index', right_on='index')\n",
    "    return emo_pos_dist_pscore\n",
    "\n",
    "def zerolistmaker(n):\n",
    "    listofzeros = [0] * n\n",
    "    return listofzeros"
   ]
  },
  {
   "source": [
    "## Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomsearchmethod(clf, param_dist, n_iter_search):\n",
    "\n",
    "    # Utility function to report best scores\n",
    "    def report(results, n_top=3):\n",
    "        for i in range(1, n_top + 1):\n",
    "            candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "            for candidate in candidates:\n",
    "                print(\"Model with rank: {0}\".format(i))\n",
    "                print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                      .format(results['mean_test_score'][candidate],\n",
    "                              results['std_test_score'][candidate]))\n",
    "                print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "                print(\"\")\n",
    "\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                       n_iter=n_iter_search)\n",
    "\n",
    "    random_search.fit(Train_X_Tfidf,Train_Y)\n",
    "    report(random_search.cv_results_)\n",
    "    \n",
    "## code attention layer\n",
    "def attention_layer(inputs, neurons):\n",
    "    x = layers.Permute((2,1))(inputs)\n",
    "    x = layers.Dense(neurons, activation=\"softmax\")(x)\n",
    "    x = layers.Permute((2,1), name=\"attention\")(x)\n",
    "    x = layers.multiply([inputs, x])\n",
    "    return x\n",
    "\n",
    "    \n",
    "def makeROC(classifiers, title, rocX_test, rocy_test):\n",
    "    # Define a result table as a DataFrame\n",
    "    result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
    "\n",
    "    # Train the models and record the results\n",
    "    for cls in classifiers:\n",
    "        model = cls\n",
    "        yproba = model.predict_proba(rocX_test)[::,1]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(rocy_test,  yproba)\n",
    "        auc = roc_auc_score(rocy_test, yproba)\n",
    "\n",
    "        result_table = result_table.append({'classifiers':cls.__class__.__name__,\n",
    "                                            'fpr':fpr, \n",
    "                                            'tpr':tpr, \n",
    "                                            'auc':auc}, ignore_index=True)\n",
    "\n",
    "    # Set name of the classifiers as index labels\n",
    "    result_table.set_index('classifiers', inplace=True)\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "    for i in result_table.index:\n",
    "        plt.plot(result_table.loc[i]['fpr'], \n",
    "                 result_table.loc[i]['tpr'], \n",
    "                 label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
    "\n",
    "    plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
    "\n",
    "    plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "    plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "    plt.title(('ROC Curve Analysis '+title), fontweight='bold', fontsize=15)\n",
    "    plt.legend(prop={'size':13}, loc='lower right')\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "source": [
    "# Data Preprocessing\n",
    "## Standardizing format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'sample_data/'\r\n",
    "SUBDIR = 'original/'\r\n",
    "\r\n",
    "df1truth = pd.read_csv(DIR + SUBDIR + \"True.csv\") \r\n",
    "df1truth[\"label\"] = \"REAL\"\r\n",
    "#First 3 words of the text column indicate the branch of the news company(reuter) that is publishing the news article\r\n",
    "#Remove the first 3 words of all text in the text column \r\n",
    "newtext = []\r\n",
    "for i in df1truth['text']:\r\n",
    "    newtext.append(' '.join(i.split(' ')[3:]))\r\n",
    "df1truth['text'] = newtext\r\n",
    "\r\n",
    "df1fake = pd.read_csv(DIR + SUBDIR + \"Fake.csv\") \r\n",
    "df1fake[\"label\"] = \"FAKE\"\r\n",
    "\r\n",
    "df2 = pd.read_csv(DIR + SUBDIR  + \"fake_or_real_news.csv\")\r\n",
    "\r\n",
    "df3 = pd.read_csv(DIR + SUBDIR + \"news_articles.csv\") \r\n",
    "df3 = df3.replace([\"Real\"], \"REAL\")\r\n",
    "df3 = df3.replace([\"Fake\"], \"FAKE\")\r\n",
    "\r\n",
    "#this dataframe is used to create CompiledNewsData.xlsx\r\n",
    "dfcompiled = pd.concat([df1truth[[\"title\",\"text\",\"label\",\"subject\"]],df1fake[[\"title\",\"text\",\"label\",\"subject\"]],df2[[\"title\",\"text\",\"label\"]],df3[[\"title\",\"text\",\"label\",\"type\"]]])\r\n",
    "dfcompiled = dfcompiled[dfcompiled['text'].notna()]\r\n",
    "maindf = dfcompiled[[\"title\",\"text\",\"label\"]]\r\n",
    "maindfG = maindf.copy()"
   ]
  },
  {
   "source": [
    "## Data Cleaning (without grammar)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Creating Cleaned dataframe without grammar\n",
    "\n",
    "stop_words = set(stop)\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#The bottom two lines will remove all stop words and stem the column text, takes very long do not run\n",
    "maindf['text'] = maindf.apply(lambda x: preprocess(x['text']), axis=1)\n",
    "maindf['title'] = maindf.apply(lambda x: preprocess(x['title']), axis=1)\n",
    "\n",
    "#Export the new cleaned data into excel file\n",
    "maindf.to_excel(DIR + 'CompiledNewsData.xlsx', index = False, header=True)"
   ]
  },
  {
   "source": [
    "## Data Cleaning (With Grammar) - For ER"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The bottom two lines will remove all stop words and stem the column text, takes very long do not run\n",
    "\n",
    "\n",
    "maindfG['text'] = maindfG.apply(lambda x: preprocessG(x['text']), axis=1)\n",
    "maindfG['title'] = maindfG.apply(lambda x: preprocessG(x['title']), axis=1)\n",
    "\n",
    "#Export the new cleaned data into excel file\n",
    "maindfG.to_excel(DIR + 'CompiledNewsDataWithGrammar.xlsx', index = False, header=True)"
   ]
  },
  {
   "source": [
    "## Converting labels and removing duplicates "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the main compiled dataframe to work with\n",
    "df = pd.read_excel(DIR + \"CompiledNewsData.xlsx\")\n",
    "dfgrammar = pd.read_excel(DIR + \"CompiledNewsDataWithGrammar.xlsx\")  \n",
    "\n",
    "#Dataframes had some duplicate titles and text\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "df['label'] = df['label'].apply(lambda x: 1 if x =='REAL' else 0)\n",
    "\n",
    "dfgrammar = dfgrammar.drop_duplicates()\n",
    "dfgrammar = dfgrammar.dropna()\n",
    "dfgrammar['label'] = dfgrammar['label'].apply(lambda x: 1 if x =='REAL' else 0)"
   ]
  },
  {
   "source": [
    "## Split data into a smaller corpus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news20 = getSmallerCorpus(df)\n",
    "news20.to_excel(DIR + 'common_df_20k.xlsx')\n",
    "news20G = getSmallerCorpus(dfgrammar)\n",
    "news20G.to_excel(DIR + 'common_df_20k_Grammar.xlsx')"
   ]
  },
  {
   "source": [
    "# EDA on whole dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## View True False proportion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = df.copy()\n",
    "print (news['label'].value_counts())\n",
    "\n",
    "Tasks = list(news[[\"title\",\"label\"]].groupby('label').count()[\"title\"])\n",
    "my_labels = 'Fake','Real'\n",
    "plt.pie(Tasks,labels=my_labels,autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Word Cloud for Real News"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile all \"labeled real into one text variable\"\n",
    "fullreal = \"\"\n",
    "for i in news[news[\"label\"] == 1][\"text\"]:\n",
    "    fullreal += (str(i) + \" \")\n",
    "    \n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(fullreal)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Word Cloud for Fake News"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile all \"labeled fake into one text variable\"\n",
    "fullfake = \"\"\n",
    "for i in news[news[\"label\"] == 0][\"text\"]:\n",
    "    fullfake += (str(i) + \" \")\n",
    "    \n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(fullfake)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# FE - Topic Modelling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = df['text']\n",
    "\n",
    "news_docs = [[w for w in new.split()] for new in news]\n",
    "news_dictionary = gensim.corpora.Dictionary(news_docs)\n",
    "news_vecs = docs2vecs(news_docs, news_dictionary)"
   ]
  },
  {
   "source": [
    " ## Finding optimal k value - Coherence Score\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run. In this case we are going to  k_max=10.\n",
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "model_list = []\n",
    "coherence_values = []\n",
    "model_topics = []\n",
    "\n",
    "for num_topics in range(2, 20, 2):\n",
    "    #sg_lda_x = gensim.models.ldamodel.LdaModel(corpus=sg_vecs, id2word=sg_dictionary, num_topics=num_topics)\n",
    "    sg_lda_x = gensim.models.wrappers.LdaMallet(mallet_path, iterations=100, corpus=news_vecs, num_topics=num_topics, id2word=news_dictionary)\n",
    "    coherencemodel = CoherenceModel(model=sg_lda_x, texts=news_docs, dictionary=news_dictionary, coherence='c_v')\n",
    "    model_topics.append(num_topics)\n",
    "    model_list.append(sg_lda_x)\n",
    "    coherence_values.append(coherencemodel.get_coherence())\n",
    "    print(\"#Topics: \" + str(num_topics) + \" Score: \" + str(coherencemodel.get_coherence()))\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "# Show graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "limit=20; start=2; step=2;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## View Top 10 words from 8 Topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics=8\n",
    "\n",
    "# mallet_path = r\"C://mallet-2.0.8/bin/mallet\" # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=news_vecs, num_topics=no_topics, id2word=news_dictionary)\n",
    "\n",
    "vecTop = ldamallet.show_topics()\n",
    "topics = []\n",
    "for i in range(0, no_topics):\n",
    "    top10values = vecTop[i][1]\n",
    "    # print (top10values)\n",
    "    topics.append([val.split('*')[1] for val in top10values.split('+')])\n",
    "\n",
    "for t in topics:\n",
    "    print (t)"
   ]
  },
  {
   "source": [
    "## View Top 10 words from 14 Topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics=14\n",
    "\n",
    "# mallet_path = r\"C://mallet-2.0.8/bin/mallet\" # update this path\n",
    "\n",
    "# save classifier\n",
    "ldamallet14 = gensim.models.wrappers.LdaMallet(mallet_path, corpus=news_vecs, num_topics=no_topics, id2word=news_dictionary)\n",
    "save_model(ldamallet14)\n",
    "    \n",
    "classifier_saved = open(\"topicModel14.pickle\", \"rb\") #binary read\n",
    "classifier_load = pickle.load(classifier_saved)\n",
    "classifier_saved.close()\n",
    "\n",
    "vecTop14 = classifier_load.show_topics(14)\n",
    "topics14 = []\n",
    "for i in range(0, no_topics):\n",
    "    top10values14 = vecTop14[i][1]\n",
    "    topics14.append([val.split('*')[1] for val in top10values14.split('+')])\n",
    "\n",
    "    \n",
    "for t in topics14:\n",
    "    print (t)"
   ]
  },
  {
   "source": [
    "## Retreive Topic Distribution for each news"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find most dominant topic\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "classifier_saved = open(\"topicModel14.pickle\", \"rb\") #binary read\n",
    "classifier_load = pickle.load(classifier_saved)\n",
    "classifier_saved.close()\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=classifier_load, corpus=news_vecs, data=news_docs)\n",
    "\n",
    "# Format\n",
    "# df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_topic_sents_keywords.columns = ['Topic 0','Topic 1','Topic 2','Topic 3','Topic 4','Topic 5', 'Topic 6','Topic 7','Topic 8','Topic 9','Topic 10','Topic 11','Topic 12','Topic 13','Text']\n",
    "\n",
    "# Show\n",
    "df_topic_sents_keywords.head(10)\n",
    "df_topic_sents_keywords.to_excel('topic_distribution_14.xlsx')"
   ]
  },
  {
   "source": [
    "# FE - Name Entity Recognition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Fake News Entities and Aggregated Domain Counts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1fake = news20G[news20G['label'] == 0]                                 # 1) Get fake news article dataframe\n",
    "index_list = df1fake.index.tolist()                                 # 2) Get index of fake dataframe\n",
    "# fakeEntityDic = getEntityDic(df1fake)                               # 3) Get sorted dict of {fake entities : count}\n",
    "# fakeTop = getTopEntityDic(fakeEntityDic, 10)                        # 4) Get dic of {entitiy type : [sorted list of top 10 entities]}\n",
    "df1_fakeEntities = addEntitiesToDataframe2(df1fake)     "
   ]
  },
  {
   "source": [
    "## View Top Entities for Fake News"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1fake = pd.read_csv(\"Fake.csv\", engine= 'python') \n",
    "# df1fake[\"label\"] = \"FAKE\"\n",
    "# df1_fakeEntities = addEntitiesToDataframe(df1fake)\n",
    "# df1_fakeEntities.to_csv(\"df1_fakeEntities.csv\", index = False)\n",
    "# print (df1_fakeEntities.head(3))\n",
    "\n",
    "# df_fake = df1fake['text'].to_frame()\n",
    "# fake_entity_dic = getEntityDic(df_fake)\n",
    "# print()\n",
    "# print(\"======================================================\")\n",
    "# getTopEntites(fake_entity_dic, 15)\n",
    "# with open('fake_entity.json', 'w') as fp:\n",
    "#     json.dump(fake_entity_dic, fp)"
   ]
  },
  {
   "source": [
    "## Real News Entities and Aggregated Domain Counts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real News\n",
    "df1true = news20G[news20G['label'] == 1]                                 # 1) Get real news article dataframe\n",
    "index_list = df1true.index.tolist()                                 # 2) Get index of real dataframe\n",
    "# trueEntityDic = getEntityDic(df1true)                               # 3) Get sorted dict of {real entities : count}\n",
    "# trueTop = getTopEntityDic(trueEntityDic, 10)                        # 4) Get dic of {entitiy type : [sorted list of top 10 entities]}\n",
    "df1_trueEntities = addEntitiesToDataframe2(df1true)                 # 5) Get DF of entities, entity count per article"
   ]
  },
  {
   "source": [
    "## View Top Entities for Fake News"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df1_trueEntities = addEntitiesToDataframe(df1truth)\n",
    "#  df1_trueEntities.to_csv(\"df1_trueEntities.csv\", index = False)\n",
    "#  df1_trueEntities.head(3)\n",
    "\n",
    "# # Cycle through true articles\n",
    "# df_true = df1truth['text'].to_frame()\n",
    "# true_entity_dic = getEntityDic(df_true)\n",
    "# print()\n",
    "# print(\"======================================================\")\n",
    "# getTopEntites(true_entity_dic, 15)\n",
    "# with open('true_entity_dic.json', 'w') as fp:\n",
    "#     json.dump(true_entity_dic, fp)"
   ]
  },
  {
   "source": [
    "## Combining into a DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Real and Fake News Dataframes\n",
    "finalEntitydf = pd.concat([df1_trueEntities, df1_fakeEntities])     # Union fake & real dataframes\n",
    "finalEntitydf.sort_index(ascending=True, inplace=True)              # Re-index them to original state\n",
    "\n",
    "# Attaching Top Entities as Column Headers to Main Dataframe                   \n",
    "finalEntitydf, store = attachTopEntities(finalEntitydf, fakeTop, trueTop)       \n",
    "\n",
    "# Get Final DF with Top Entity counts\n",
    "mainEntitydf = getFinalEntityDF(finalEntitydf, store)\n",
    "\n",
    "del mainEntitydf['person entities']\n",
    "del mainEntitydf['organisation entities']\n",
    "del mainEntitydf['location entities']\n",
    "del emotional_df_stack_groupped_pos['Unnamed: 0']"
   ]
  },
  {
   "source": [
    "# POS Tag, Emotions/Sentiment Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Generate Emotion Distribution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = generate_emotions(news20)\n",
    "emp_df.to_excel('emotion_analysis_final.xlsx')\n",
    "emp_df = pd.read_excel('emotion_analysis_final.xlsx')\n",
    "\n",
    "# Generating the POS tag dist \n",
    "emo_pos_df = generate_pos_tag_dist(emp_df)\n",
    "emp_df = emp_df.reset_index()\n",
    "emp_df = emp_df[emp_df.columns.drop(list(emp_df.filter(regex='index')))]\n",
    "emp_df = emp_df.rename(columns={emp_df.columns[0]: 'index'})\n",
    "comb_emo_pos_dist =  emp_df.merge(emo_pos_df, left_on='index', right_on='index')\n",
    "\n",
    "# genrating vader text \n",
    "emo_pos_dist_pscore = vader_score_generation(comb_emo_pos_dist)\n",
    "emo_pos_dist_pscore.to_excel('emo_pos_dist_pscore.xlsx')\n",
    "\n",
    "# Generating of Pos Grouping Features \n",
    "emotional_df_stack = pd.read_excel('emo_pos_dist_pscore.xlsx')\n",
    "del emotional_df_stack['compound']\n",
    "\n",
    "emotional_df_stack_groupped_pos, pos_tags = group_pos_features(emotional_df_stack)\n",
    "emotional_df_stack_groupped_pos = emotional_df_stack_groupped_pos.loc[:, (emotional_df_stack_groupped_pos != 0).any(axis=0)]\n",
    "emotional_df_stack_groupped_pos.to_excel('pos_groupings_vader_emotion.xlsx')\n"
   ]
  },
  {
   "source": [
    "## Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### PCA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA \n",
    "emotional_df_stack = pd.read_excel('pos_groupings_vader_emotion.xlsx')\n",
    "news_pca = emotional_df_stack.iloc[:, 5:]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "news_pca_components = pca.fit_transform(news_pca)\n",
    "principalDf = pd.DataFrame(data = news_pca_components, columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([principalDf, news_pca[['label']]], axis = 1) \n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = [1,0]\n",
    "colors = ['r', 'g']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['label'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "source": [
    "### Covariance Matrix (Sentiments and Emotions)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Corrvariance value \n",
    "corr_sentiment_emotion = pd.read_excel('sentiment_emotion_corr.xlsx')\n",
    "c = corr_sentiment_emotion.corr().abs()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\")\n",
    "print(so[:-14])\n",
    "\n",
    "# Covariance heatmap \n",
    "cov_mat = corr_sentiment_emotion.corr()\n",
    "# plot the heatmap\n",
    "sn.heatmap(cov_mat, \n",
    "        xticklabels=cov_mat.columns,\n",
    "        yticklabels=cov_mat.columns)"
   ]
  },
  {
   "source": [
    "### Overall Distribution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emotions\n",
    "plotting_df_emotion_senti_pso = emotional_df_stack.iloc[:, 4:]\n",
    "plotting_df_emotion_senti_pso.groupby('label').mean().reset_index().plot(x=\"label\", y=[\"Happy\", \"Angry\", \"Surprise\", \"Sad\", \"Fear\"], kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tag\n",
    "plotting_df_emotion_senti_pso.groupby('label').mean().reset_index().plot(x=\"label\", y=list(pos_tags), kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tag groupings\n",
    "pos_groups_dist = emotional_df_stack.columns[-9:]\n",
    "emotional_df_stack.groupby('label').mean().reset_index().plot(x=\"label\", y=pos_groups_dist, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiments\n",
    "vader_tags = ['neg','neu','pos']\n",
    "plotting_df_emotion_senti_pso.groupby('label').mean().reset_index().plot(x=\"label\", y=vader_tags, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for classification\n",
    "emotional_df_stack.drop(columns=pos_tags, inplace=True)\n",
    "emotional_df_stack = emotional_df_stack.loc[:, (emotional_df_stack != 0).any(axis=0)]\n",
    "emotional_df_stack.to_excel('pos_groupings_vader_emotion_final.xlsx')\n",
    "\n",
    "horizontal_stack = emotional_df_stack.merge(mainEntitydf, how='left', on='index')\n",
    "horizontal_stack = horizontal_stack.loc[:,~horizontal_stack.columns.duplicated()]\n",
    "\n",
    "# uncomment if needed\n",
    "# del horizontal_stack['label']\n",
    "# del horizontal_stack['label_x']\n",
    "# del horizontal_stack['title_y']\n",
    "# del horizontal_stack['text_y']\n",
    "# del horizontal_stack[',']\n",
    "# del horizontal_stack['.']\n",
    "horizontal_stack.to_excel('final_feature_engineered.xlsx')"
   ]
  },
  {
   "source": [
    "# Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Train Test Split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(df['text'],df['label'],test_size=0.3)"
   ]
  },
  {
   "source": [
    "## Generate Word Vector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulllist = []\n",
    "for i in df['text']:\n",
    "    fulllist.append(i)\n",
    "\n",
    "#Set maxfeatures to 5000 maybe next time0\n",
    "Tfidf_vect = TfidfVectorizer(max_features=None)\n",
    "Tfidf_vect.fit(fulllist)\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "source": [
    "## Stochastic Gradient Descent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD = SGDClassifier(loss='log', penalty='l2', alpha=1e-3, n_iter_no_change=5)\n",
    "\n",
    "param_dist = {\n",
    "    'penalty': ['elasticnet','l2'],\n",
    "    'alpha': [10 ** x for x in range(-6, 1)],\n",
    "    'l1_ratio': [0, 0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1],\n",
    "}\n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "randomsearchmethod(SGD,param_dist, n_iter_search)"
   ]
  },
  {
   "source": [
    "## ADA Boost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADA = AdaBoostClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    'learning_rate' : [0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1],\n",
    "    'n_estimators': [100,200,300,400],\n",
    "    'base_estimator': [DecisionTreeClassifier(random_state=0, max_depth=1), DecisionTreeClassifier(random_state=0, max_depth=2),DecisionTreeClassifier(random_state=0, max_depth=3)]\n",
    "}\n",
    "\n",
    "n_iter_search = 3\n",
    "\n",
    "randomsearchmethod(ADA,param_dist, n_iter_search)"
   ]
  },
  {
   "source": [
    "## Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': [5,10,15,20,25],\n",
    "    'n_estimators': [70,80,85,90,100]\n",
    "}\n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "randomsearchmethod(RF,param_dist, n_iter_search)"
   ]
  },
  {
   "source": [
    "## XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': [0,5,10,15,20,25],\n",
    "    'n_estimators': [50, 100, 150, 200, 250],\n",
    "    'reg_alpha': [0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1]\n",
    "}\n",
    "\n",
    "n_iter_search = 3\n",
    "\n",
    "randomsearchmethod(XGB,param_dist, n_iter_search)"
   ]
  },
  {
   "source": [
    "## LSTM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Word2Vec Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = gensim_api.load(\"word2vec-google-news-300\")\n",
    "## create list of lists of unigrams\n",
    "corpus = Train_X\n",
    "\n",
    "lst_corpus = []\n",
    "for string in corpus:\n",
    "   lst_words = string.split()\n",
    "   lst_grams = [\" \".join(lst_words[i:i+1]) \n",
    "               for i in range(0, len(lst_words), 1)]\n",
    "   lst_corpus.append(lst_grams)\n",
    "\n",
    "bigrams_detector = gensim.models.phrases.Phrases(lst_corpus, delimiter=\" \".encode(), min_count=5, threshold=10)\n",
    "bigrams_detector = gensim.models.phrases.Phraser(bigrams_detector)\n",
    "\n",
    "nlp = gensim.models.word2vec.Word2Vec(lst_corpus, size=300, window=8, min_count=1, sg=1, iter=30)\n",
    "\n",
    "## tokenize text\n",
    "tokenizer = kprocessing.text.Tokenizer(lower=True, split=' ', \n",
    "                     oov_token=\"NaN\", \n",
    "                     filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(lst_corpus)\n",
    "dic_vocabulary = tokenizer.word_index\n",
    "## create sequence\n",
    "lst_text2seq= tokenizer.texts_to_sequences(lst_corpus)\n",
    "## padding sequence\n",
    "X_train = kprocessing.sequence.pad_sequences(lst_text2seq, \n",
    "                    maxlen=15, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "corpus = Test_X\n",
    "\n",
    "## create list of n-grams\n",
    "lst_corpus = []\n",
    "for string in corpus:\n",
    "    lst_words = string.split()\n",
    "    lst_grams = [\" \".join(lst_words[i:i+1]) for i in range(0, \n",
    "                 len(lst_words), 1)]\n",
    "    lst_corpus.append(lst_grams)\n",
    "    \n",
    "## detect common bigrams using the fitted detectors\n",
    "lst_corpus = list(bigrams_detector[lst_corpus])\n",
    "## text to sequence with the fitted tokenizer\n",
    "lst_text2seq = tokenizer.texts_to_sequences(lst_corpus)\n",
    "\n",
    "## padding sequence\n",
    "X_test = kprocessing.sequence.pad_sequences(lst_text2seq, maxlen=15,\n",
    "             padding=\"post\", truncating=\"post\")\n",
    "\n",
    "## start the matrix (length of vocabulary x vector size) with all 0s\n",
    "embeddings = np.zeros((len(dic_vocabulary)+1, 300))\n",
    "for word,idx in dic_vocabulary.items():\n",
    "    ## update the row with vector\n",
    "    try:\n",
    "        embeddings[idx] =  nlp[word]\n",
    "    ## if word not in model then skip and the row stays all 0s\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "source": [
    "### Declare NN Layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## input\n",
    "x_in = layers.Input(shape=(15,))\n",
    "## embedding\n",
    "x = layers.Embedding(input_dim=embeddings.shape[0],  \n",
    "                     output_dim=embeddings.shape[1], \n",
    "                     weights=[embeddings],\n",
    "                     input_length=15, trainable=False)(x_in)\n",
    "## apply attention\n",
    "x = attention_layer(x, neurons=15)\n",
    "## 2 layers of bidirectional lstm\n",
    "x = layers.Bidirectional(layers.LSTM(units=15, dropout=0.3, \n",
    "                         return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(units=15, dropout=0.3))(x)\n",
    "## final dense layers\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "y_out = layers.Dense(2, activation='softmax')(x)\n",
    "## compile\n",
    "NNmodel = models.Model(x_in, y_out)\n",
    "NNmodel.compile(loss=tensorflow.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "NNmodel.summary()"
   ]
  },
  {
   "source": [
    "### Traning the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encode y\n",
    "dic_y_mapping = {n:label for n,label in \n",
    "                 enumerate(np.unique(Train_Y))}\n",
    "inverse_dic = {v:k for k,v in dic_y_mapping.items()}\n",
    "y_train = np.array([inverse_dic[y] for y in Train_Y])\n",
    "## train\n",
    "training = NNmodel.fit(x=X_train, y=y_train, batch_size=256, epochs=2, shuffle=True, verbose=0, validation_split=0.2)\n",
    "## plot loss and accuracy\n",
    "metrics = [k for k in training.history.keys() if (\"loss\" not in k) and (\"val\" not in k)]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True)\n",
    "ax[0].set(title=\"Training\")\n",
    "ax11 = ax[0].twinx()\n",
    "ax[0].plot(training.history['loss'], color='black')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss', color='black')\n",
    "for metric in metrics:\n",
    "    ax11.plot(training.history[metric], label=metric)\n",
    "ax11.set_ylabel(\"Score\", color='steelblue')\n",
    "ax11.legend()\n",
    "ax[1].set(title=\"Validation\")\n",
    "ax22 = ax[1].twinx()\n",
    "ax[1].plot(training.history['val_loss'], color='black')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss', color='black')\n",
    "for metric in metrics:\n",
    "     ax22.plot(training.history['val_'+metric], label=metric)\n",
    "ax22.set_ylabel(\"Score\", color=\"steelblue\")\n",
    "plt.show()\n",
    "\n",
    "## Prediction\n",
    "predicted_prob = NNmodel.predict(X_test)\n",
    "predicted = [dic_y_mapping[np.argmax(pred)] for pred in \n",
    "             predicted_prob]"
   ]
  },
  {
   "source": [
    "## Accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace ngram_range = (1,2) for bigram\n",
    "NB = MultinomialNB().fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "SGD = SGDClassifier(loss='log', penalty= 'l2', l1_ratio= 0.05, alpha= 1e-05, n_iter_no_change=5).fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "ADA = AdaBoostClassifier(n_estimators= 300, learning_rate= 0.2, base_estimator= DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,)).fit(Train_X_Tfidf, Train_Y)\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=100, max_depth=25, random_state=0).fit(Train_X_Tfidf, Train_Y)\n",
    "\n",
    "XGB = XGBClassifier(n_estimators = 200, max_depth=15, reg_alpha=0.05).fit(Train_X_Tfidf, Train_Y)\n",
    "\n",
    "# Save to file in the current working directory\n",
    "pkl_filename = \"BaseTFIDFNB.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(NB, file)\n",
    "\n",
    "pkl_filename = \"BaseTFIDFSGD.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(SGD, file)\n",
    "\n",
    "pkl_filename = \"BaseTFIDFADA.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(ADA, file)\n",
    "\n",
    "pkl_filename = \"BaseTFIDFRF.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(RF, file)\n",
    "\n",
    "pkl_filename = \"BaseTFIDFXGB.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(XGB, file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseTFIDFNB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    NB = pickle.load(file)\n",
    "predictions_NB = NB.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****NB Report****\")\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(Test_Y, predictions_NB))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y, predictions_NB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y, predictions_NB)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseTFIDFSGD.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    SGD = pickle.load(file)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SGD = SGD.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****SGD Report****\")\n",
    "print(\"SGD Accuracy:\",metrics.accuracy_score(Test_Y, predictions_SGD))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y, predictions_SGD))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y, predictions_SGD))\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseTFIDFADA.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    ADA = pickle.load(file)\n",
    "predictions_ADA = ADA.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****ADABoost Report****\")\n",
    "print(\"AdaBoostClassifier Accuracy:\",metrics.accuracy_score(Test_Y, predictions_ADA))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y, predictions_ADA))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y, predictions_ADA) )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseTFIDFRF.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    RF = pickle.load(file)\n",
    "predictions_RF = RF.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****RF Report****\")\n",
    "print(\"RandomForest Accuracy:\",metrics.accuracy_score(Test_Y, predictions_RF))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y, predictions_RF))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y, predictions_RF)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseTFIDFXGB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    XGB = pickle.load(file)\n",
    "predictions_XGB = XGB.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****XGB Report****\")\n",
    "print(\"XGBoost Accuracy:\",metrics.accuracy_score(Test_Y, predictions_XGB))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y, predictions_XGB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y, predictions_XGB)  )\n",
    "\n",
    "print(\"****LSTM Report****\")\n",
    "print(\"LSTM Accuracy:\",metrics.accuracy_score(Test_Y, predicted))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y, predicted))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y, predicted)  )"
   ]
  },
  {
   "source": [
    "## ROC "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "makeROC([NB, XGB, RF, ADA, SGD],\"TFIDF Real Vs Fake Performance\", Test_X_Tfidf, Test_Y)"
   ]
  },
  {
   "source": [
    "## Importing and joining data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfemotion = pd.read_excel(\"sample_data/pos_groupings_vader_emotion.xlsx\")\n",
    "dfemotion = dfemotion.drop(['text','title','Unnamed: 0','index','label_y','compound'], axis=1)\n",
    "dftopic = pd.read_excel(\"sample_data/topic_distribution_14.xlsx\")\n",
    "dftopic = dftopic.drop(['Unnamed: 0','Text'], axis=1)\n",
    "\n",
    "entity = pd.read_csv(\"sample_data/Entity_final.csv\")\n",
    "entity = entity.drop(['title','text','label','index','person entities','organisation entities','location entities'], axis=1)\n",
    "\n",
    "#Split text set to 20k rows\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(df['text'],df['label'],train_size= 0.45, stratify=df['label'], random_state=0)\n",
    "\n",
    "#TFIDF Vectorize New Sample Set\n",
    "fulllist = []\n",
    "for i in Train_X:\n",
    "    fulllist.append(i)\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(fulllist)\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "\n",
    "#Convert to dataframe\n",
    "Train_X_df = pd.DataFrame(Train_X_Tfidf.toarray(), columns=Tfidf_vect.get_feature_names())\n",
    "Train_Y = Train_Y.fillna(0)\n",
    "\n",
    "#Combine dataframes\n",
    "dftopic = pd.concat([dftopic, Train_X_df], axis=1)\n",
    "dfemotion = pd.concat([dfemotion, entity[['person entity count', 'organisation entity count' , 'location entity count']]], axis=1)\n",
    "save_y = Train_Y.copy()\n",
    "\n",
    "#Create test and train text set\n",
    "Train_X_Topic, Test_X_Topic, Train_Y_Topic, Test_Y_Topic = model_selection.train_test_split(dftopic,Train_Y, train_size= 0.4, stratify=Train_Y, random_state=0)\n",
    "Train_X_Emotion, Test_X_Emotion, Train_Y_Emotion, Test_Y_Emotion = model_selection.train_test_split(dfemotion,Train_Y, train_size= 0.4, stratify=Train_Y, random_state=0)\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Train_X_df,Train_Y,train_size= 0.4, stratify=Train_Y, random_state=0)"
   ]
  },
  {
   "source": [
    "## Base Model Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace ngram_range = (1,2) for bigram\n",
    "TFIDFNB = MultinomialNB().fit(Train_X,Train_Y)\n",
    "\n",
    "TFIDFSGD = SGDClassifier(loss='log', penalty= 'l2', l1_ratio= 0.05, alpha= 1e-05, n_iter_no_change=5).fit(Train_X,Train_Y)\n",
    "\n",
    "TFIDFADA = AdaBoostClassifier(n_estimators= 300, learning_rate= 0.2, base_estimator= DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,)).fit(Train_X,Train_Y)\n",
    "\n",
    "TFIDFRF = RandomForestClassifier(n_estimators=100, max_depth=25, random_state=0).fit(Train_X,Train_Y)\n",
    "\n",
    "TFIDFXGB = XGBClassifier(n_estimators = 200, max_depth=15, reg_alpha=0.05).fit(Train_X,Train_Y)\n",
    "\n",
    "# Save to file in the current working directory\n",
    "pkl_filename = \"BaseExtractTFIDFNB.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(TFIDFNB, file)\n",
    "\n",
    "pkl_filename = \"BaseExtractTFIDFSGD.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(TFIDFSGD, file)\n",
    "\n",
    "pkl_filename = \"BaseExtractTFIDFADA.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(TFIDFADA, file)\n",
    "\n",
    "pkl_filename = \"BaseExtractTFIDFRF.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(TFIDFRF, file)\n",
    "\n",
    "pkl_filename = \"BaseExtractTFIDFXGB.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(TFIDFXGB, file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseExtractTFIDFNB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TFIDFNB = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseExtractTFIDFSGD.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TFIDFSGD = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseExtractTFIDFADA.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TFIDFADA = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseExtractTFIDFRF.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TFIDFRF = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseExtractTFIDFXGB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TFIDFXGB = pickle.load(file)\n",
    "\n",
    "# replace ngram_range = (1,2) for bigram\n",
    "predictions_NB = TFIDFNB.predict(Test_X)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****NB Report****\")\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(Test_Y, predictions_NB))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y, predictions_NB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y, predictions_NB)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SGD = TFIDFSGD.predict(Test_X)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****SGD Report****\")\n",
    "print(\"SGD Accuracy:\",metrics.accuracy_score(Test_Y, predictions_SGD))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y, predictions_SGD))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y, predictions_SGD))\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_ADA = TFIDFADA.predict(Test_X)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****ADABoost Report****\")\n",
    "print(\"AdaBoostClassifier Accuracy:\",metrics.accuracy_score(Test_Y, predictions_ADA))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y, predictions_ADA))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y, predictions_ADA) )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_RF = TFIDFRF.predict(Test_X)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****RF Report****\")\n",
    "print(\"RandomForest Accuracy:\",metrics.accuracy_score(Test_Y, predictions_RF))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y, predictions_RF))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y, predictions_RF)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_XGB = TFIDFXGB.predict(Test_X)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****XGB Report****\")\n",
    "print(\"XGBoost Accuracy:\",metrics.accuracy_score(Test_Y, predictions_XGB))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y, predictions_XGB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y, predictions_XGB)  )"
   ]
  },
  {
   "source": [
    "## Base + Topic Model Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*36)\n",
    "print(\"SGD Optimization\")\n",
    "SGD = SGDClassifier(loss='log', penalty='l2', alpha=1e-3, n_iter_no_change=5)\n",
    "param_dist = {\n",
    "    'penalty': ['elasticnet','l2'],\n",
    "    'alpha': [10 ** x for x in range(-6, 1)],\n",
    "    'l1_ratio': [0, 0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1],\n",
    "}\n",
    "n_iter_search = 20\n",
    "randomsearchmethod(SGD,param_dist, n_iter_search, Train_X_Topic,Train_Y_Topic)\n",
    "\n",
    "print(\"*\"*36)\n",
    "print(\"ADABoost Optimization\")\n",
    "ADA = AdaBoostClassifier()\n",
    "param_dist = {\n",
    "    'learning_rate' : [0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1],\n",
    "    'n_estimators': [100,200,300,400],\n",
    "    'base_estimator': [DecisionTreeClassifier(random_state=0, max_depth=1), DecisionTreeClassifier(random_state=0, max_depth=2),DecisionTreeClassifier(random_state=0, max_depth=3)]\n",
    "}\n",
    "n_iter_search = 2\n",
    "randomsearchmethod(ADA,param_dist, n_iter_search, Train_X_Topic,Train_Y_Topic)\n",
    "\n",
    "#Restart this one it ran on emotion\n",
    "print(\"*\"*36)\n",
    "print(\"Random Forest Optimization\")\n",
    "RF = RandomForestClassifier()\n",
    "param_dist = {\n",
    "    'max_depth': [5,10,15,20,25,30,35,40],\n",
    "    'n_estimators': [70,80,85,90,100,110,120,130,140]\n",
    "}\n",
    "n_iter_search = 20\n",
    "randomsearchmethod(RF,param_dist, n_iter_search, Train_X_Topic,Train_Y_Topic)\n",
    "\n",
    "print(\"*\"*36)\n",
    "print(\"XGBoost Optimization\")\n",
    "XGB = XGBClassifier()\n",
    "param_dist = {\n",
    "    'max_depth': [0,5,10,15,20,25],\n",
    "    'n_estimators': [50, 100, 150, 200, 250],\n",
    "    'reg_alpha': [0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1]\n",
    "}\n",
    "n_iter_search = 2\n",
    "randomsearchmethod(XGB,param_dist, n_iter_search, Train_X_Topic,Train_Y_Topic)\n",
    "\n",
    "# Save Data\n",
    "TopicADA = AdaBoostClassifier(n_estimators= 350, learning_rate= 0.1, base_estimator= DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,)).fit(Train_X_Topic,Train_Y_Topic)\n",
    "\n",
    "pkl_filename = \"TopicTFIDFADA.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(TopicADA, file)\n",
    "\n",
    "    # replace ngram_range = (1,2) for bigram\n",
    "TopicNB = MultinomialNB().fit(Train_X_Topic,Train_Y_Topic)\n",
    "\n",
    "TopicSGD = SGDClassifier(loss='log', penalty= 'elasticnet', l1_ratio= 0.1, alpha= 0.0001, n_iter_no_change=5).fit(Train_X_Topic,Train_Y_Topic)\n",
    "\n",
    "TopicADA = AdaBoostClassifier(n_estimators= 350, learning_rate= 0.1, base_estimator= DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,)).fit(Train_X_Topic,Train_Y_Topic)\n",
    "\n",
    "TopicRF = RandomForestClassifier(n_estimators=140, max_depth=40, random_state=0).fit(Train_X_Topic,Train_Y_Topic)\n",
    "\n",
    "TopicXGB = XGBClassifier(n_estimators = 120, max_depth=10, reg_alpha=0.8).fit(Train_X_Topic,Train_Y_Topic)\n",
    "\n",
    "# Save to file in the current working directory\n",
    "pkl_filename = \"TopicTFIDFNB.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(TopicNB, file)\n",
    "\n",
    "pkl_filename = \"TopicTFIDFSGD.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(TopicSGD, file)\n",
    "\n",
    "pkl_filename = \"TopicTFIDFADA.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(TopicADA, file)\n",
    "\n",
    "pkl_filename = \"TopicTFIDFRF.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(TopicRF, file)\n",
    "\n",
    "pkl_filename = \"TopicTFIDFXGB.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(TopicXGB, file)\n",
    "\n",
    "\n",
    "    # Load from file\n",
    "pkl_filename = \"TopicTFIDFNB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TopicNB = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"TopicTFIDFSGD.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TopicSGD = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"TopicTFIDFADA.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TopicADA = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"TopicTFIDFRF.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TopicRF = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"TopicTFIDFXGB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TopicXGB = pickle.load(file)\n",
    "\n",
    "predictions_NB = TopicNB.predict(Test_X_Topic)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****NB Report****\")\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(Test_Y_Topic, predictions_NB))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_Topic, predictions_NB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_Topic, predictions_NB)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SGD = TopicSGD.predict(Test_X_Topic)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****SGD Report****\")\n",
    "print(\"SGD Accuracy:\",metrics.accuracy_score(Test_Y_Topic, predictions_SGD))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_Topic, predictions_SGD))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_Topic, predictions_SGD))\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_ADA = TopicADA.predict(Test_X_Topic)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****ADABoost Report****\")\n",
    "print(\"AdaBoostClassifier Accuracy:\",metrics.accuracy_score(Test_Y_Topic, predictions_ADA))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_Topic, predictions_ADA))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_Topic, predictions_ADA) )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_RF = TopicRF.predict(Test_X_Topic)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****RF Report****\")\n",
    "print(\"RandomForest Accuracy:\",metrics.accuracy_score(Test_Y_Topic, predictions_RF))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_Topic, predictions_RF))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_Topic, predictions_RF)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_XGB = TopicXGB.predict(Test_X_Topic)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****XGB Report****\")\n",
    "print(\"XGBoost Accuracy:\",metrics.accuracy_score(Test_Y_Topic, predictions_XGB))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_Topic, predictions_XGB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_Topic, predictions_XGB)  )\n",
    "\n",
    "## ROC \n",
    "makeROC([TopicNB, TopicXGB, TopicRF, TopicADA, TopicSGD],\"TFIDF + Topic probabilities Real Vs Fake Performance\", Test_X_Topic, Test_Y_Topic)"
   ]
  },
  {
   "source": [
    "## Generic Model Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*36)\n",
    "print(\"SGD Optimization\")\n",
    "SGD = SGDClassifier(loss='log', penalty='l2', alpha=1e-3, n_iter_no_change=5)\n",
    "param_dist = {\n",
    "    'penalty': ['elasticnet','l2'],\n",
    "    'alpha': [10 ** x for x in range(-6, 1)],\n",
    "    'l1_ratio': [0, 0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1],\n",
    "}\n",
    "n_iter_search = 20\n",
    "randomsearchmethod(SGD,param_dist, n_iter_search, Train_X_Emotion,Train_Y_Emotion)\n",
    "\n",
    "print(\"*\"*36)\n",
    "print(\"ADABoost Optimization\")\n",
    "ADA = AdaBoostClassifier()\n",
    "param_dist = {\n",
    "    'learning_rate' : [0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1],\n",
    "    'n_estimators': [100,200,300,400],\n",
    "    'base_estimator': [DecisionTreeClassifier(random_state=0, max_depth=1), DecisionTreeClassifier(random_state=0, max_depth=2),DecisionTreeClassifier(random_state=0, max_depth=3)]\n",
    "}\n",
    "n_iter_search = 20\n",
    "randomsearchmethod(ADA,param_dist, n_iter_search, Train_X_Emotion,Train_Y_Emotion)\n",
    "\n",
    "print(\"*\"*36)\n",
    "print(\"Random Forest Optimization\")\n",
    "RF = RandomForestClassifier()\n",
    "param_dist = {\n",
    "    'max_depth': [5,10,15,20,25,30,35,40],\n",
    "    'n_estimators': [70,80,85,90,100,110,120,130,140]\n",
    "}\n",
    "n_iter_search = 20\n",
    "randomsearchmethod(RF,param_dist, n_iter_search, Train_X_Emotion,Train_Y_Emotion)\n",
    "\n",
    "print(\"*\"*36)\n",
    "print(\"XGBoost Optimization\")\n",
    "XGB = XGBClassifier()\n",
    "param_dist = {\n",
    "    'max_depth': [0,5,10,15,20,25],\n",
    "    'n_estimators': [50, 100, 150, 200, 250],\n",
    "    'reg_alpha': [0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1]\n",
    "}\n",
    "n_iter_search = 20\n",
    "randomsearchmethod(XGB,param_dist, n_iter_search, Train_X_Emotion,Train_Y_Emotion)\n",
    "\n",
    "# replace ngram_range = (1,2) for bigram\n",
    "EmotionNB = MultinomialNB().fit(Train_X_Emotion,Train_Y_Emotion)\n",
    "\n",
    "EmotionSGD = SGDClassifier(loss='log', penalty= 'elasticnet', l1_ratio= 0.8, alpha= 1e-05, n_iter_no_change=5).fit(Train_X_Emotion,Train_Y_Emotion)\n",
    "\n",
    "EmotionADA = AdaBoostClassifier(n_estimators= 400, learning_rate= 0.1, base_estimator= DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,)).fit(Train_X_Emotion,Train_Y_Emotion)\n",
    "\n",
    "EmotionRF = RandomForestClassifier(n_estimators=130, max_depth=40, random_state=0).fit(Train_X_Emotion,Train_Y_Emotion)\n",
    "\n",
    "EmotionXGB = XGBClassifier(n_estimators = 250, max_depth=20, reg_alpha=0.05).fit(Train_X_Emotion,Train_Y_Emotion)\n",
    "\n",
    "# Save to file in the current working directory\n",
    "pkl_filename = \"EmotionNB.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(EmotionNB, file)\n",
    "\n",
    "pkl_filename = \"EmotionSGD.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(EmotionSGD, file)\n",
    "\n",
    "pkl_filename = \"EmotionADA.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(EmotionADA, file)\n",
    "\n",
    "pkl_filename = \"EmotionRF.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(EmotionRF, file)\n",
    "\n",
    "pkl_filename = \"EmotionXGB.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(EmotionXGB, file)\n",
    "\n",
    "    # Load from file\n",
    "pkl_filename = \"EmotionNB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionNB = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"EmotionSGD.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionSGD = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"EmotionADA.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionADA = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"EmotionRF.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionRF = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"EmotionXGB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionXGB = pickle.load(file)\n",
    "\n",
    "predictions_NB = EmotionNB.predict(Test_X_Emotion)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****NB Report****\")\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(Test_Y_Emotion, predictions_NB))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_Emotion, predictions_NB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_Emotion, predictions_NB)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SGD = EmotionSGD.predict(Test_X_Emotion)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****SGD Report****\")\n",
    "print(\"SGD Accuracy:\",metrics.accuracy_score(Test_Y_Emotion, predictions_SGD))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_Emotion, predictions_SGD))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_Emotion, predictions_SGD))\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_ADA = EmotionADA.predict(Test_X_Emotion)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****ADABoost Report****\")\n",
    "print(\"AdaBoostClassifier Accuracy:\",metrics.accuracy_score(Test_Y_Emotion, predictions_ADA))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_Emotion, predictions_ADA))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_Emotion, predictions_ADA) )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_RF = EmotionRF.predict(Test_X_Emotion)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****RF Report****\")\n",
    "print(\"RandomForest Accuracy:\",metrics.accuracy_score(Test_Y_Emotion, predictions_RF))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_Emotion, predictions_RF))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_Emotion, predictions_RF)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_XGB = EmotionXGB.predict(Test_X_Emotion)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****XGB Report****\")\n",
    "print(\"XGBoost Accuracy:\",metrics.accuracy_score(Test_Y_Emotion, predictions_XGB))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_Emotion, predictions_XGB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_Emotion, predictions_XGB)  )\n",
    "\n",
    "#ROC\n",
    "makeROC([ EmotionNB, EmotionXGB, EmotionRF, EmotionADA, EmotionSGD],\"Sentiment, POS, and Entity Real Vs Fake Performance\", Test_X_Emotion, Test_Y_Emotion)\n",
    "\n",
    "# Feature Importance\n",
    "# Load from file\n",
    "pkl_filename = \"EmotionADA.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionADA = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"EmotionXGB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionXGB = pickle.load(file)\n",
    "    \n",
    "# Load from file\n",
    "pkl_filename = \"EmotionRF.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionRF = pickle.load(file)\n",
    "\n",
    "featurenames = EmotionXGB.get_booster().feature_names\n",
    "\n",
    "pyplot.barh(range(len(EmotionADA.feature_importances_)), EmotionADA.feature_importances_)\n",
    "plt.yticks(range(len(featurenames)), featurenames)\n",
    "plt.title('ADABoost Feature Importance')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.barh(range(len(EmotionRF.feature_importances_)), EmotionRF.feature_importances_)\n",
    "plt.yticks(range(len(featurenames)), featurenames)\n",
    "plt.title('Random Forest Feature Importance')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.barh(range(len(EmotionXGB.feature_importances_)), EmotionXGB.feature_importances_)\n",
    "plt.yticks(range(len(featurenames)), featurenames)\n",
    "plt.title('XGBoost Feature Importance')\n",
    "pyplot.show()"
   ]
  },
  {
   "source": [
    "## Overall (All Features) Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftopiccleaned = dftopic.drop(['neg'], axis = 1)\n",
    "dfoverall = pd.concat([dftopiccleaned, dfemotion], axis=1)\n",
    "\n",
    "#In case any columns are duplicated\n",
    "#dfoverall = dfoverall.loc[:,~dfoverall.columns.duplicated()]\n",
    "\n",
    "Train_X_overall, Test_X_overall, Train_Y_overall, Test_Y_overall = model_selection.train_test_split(dfoverall,save_y,train_size= 0.4, stratify=save_y, random_state=0)\n",
    "\n",
    "print(\"*\"*36)\n",
    "print(\"SGD Optimization\")\n",
    "SGD = SGDClassifier(loss='log', penalty='l2', alpha=1e-3, n_iter_no_change=5)\n",
    "param_dist = {\n",
    "    'penalty': ['elasticnet','l2'],\n",
    "    'alpha': [10 ** x for x in range(-6, 1)],\n",
    "    'l1_ratio': [0, 0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1],\n",
    "}\n",
    "n_iter_search = 20\n",
    "randomsearchmethod(SGD,param_dist, n_iter_search, Train_X_overall,Train_Y_overall)\n",
    "\n",
    "print(\"*\"*36)\n",
    "print(\"ADABoost Optimization\")\n",
    "ADA = AdaBoostClassifier()\n",
    "param_dist = {\n",
    "    'learning_rate' : [0.05, 0.1, 0.2, 0.5],\n",
    "    'n_estimators': [100,200,300,400],\n",
    "    'base_estimator': [DecisionTreeClassifier(random_state=0, max_depth=2),DecisionTreeClassifier(random_state=0, max_depth=3)]\n",
    "}\n",
    "n_iter_search = 2\n",
    "randomsearchmethod(ADA,param_dist, n_iter_search, Train_X_overall,Train_Y_overall)\n",
    "\n",
    "#Restart this one it ran on emotion\n",
    "print(\"*\"*36)\n",
    "print(\"Random Forest Optimization\")\n",
    "RF = RandomForestClassifier()\n",
    "param_dist = {\n",
    "    'max_depth': [30,35,40],\n",
    "    'n_estimators': [110,120,130,140]\n",
    "}\n",
    "n_iter_search = 20\n",
    "randomsearchmethod(RF,param_dist, n_iter_search, Train_X_overall,Train_Y_overall)\n",
    "\n",
    "print(\"*\"*36)\n",
    "print(\"XGBoost Optimization\")\n",
    "XGB = XGBClassifier()\n",
    "param_dist = {\n",
    "    'max_depth': [15,20,25],\n",
    "    'n_estimators': [ 150, 200, 250],\n",
    "    'reg_alpha': [0.05, 0.1, 0.2, 0.5]\n",
    "}\n",
    "n_iter_search = 2\n",
    "randomsearchmethod(XGB,param_dist, n_iter_search, Train_X_overall,Train_Y_overall)\n",
    "\n",
    "# replace ngram_range = (1,2) for bigram\n",
    "OverallNB = MultinomialNB().fit(Train_X_Topic,Train_Y_Topic)\n",
    "\n",
    "OverallSGD = SGDClassifier(loss='log', penalty= 'elasticnet', l1_ratio= 0.1, alpha= 0.0001, n_iter_no_change=5).fit(Train_X_overall,Train_Y_overall)\n",
    "\n",
    "OverallADA = AdaBoostClassifier(n_estimators= 300, learning_rate= 0.1, base_estimator= DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,)).fit(Train_X_overall,Train_Y_overall)\n",
    "\n",
    "OverallRF = RandomForestClassifier(n_estimators=140, max_depth=30, random_state=0).fit(Train_X_overall,Train_Y_overall)\n",
    "\n",
    "OverallXGB = XGBClassifier(n_estimators = 200, max_depth=25, reg_alpha=0.1).fit(Train_X_overall,Train_Y_overall)\n",
    "\n",
    "# Save to file in the current working directory\n",
    "pkl_filename = \"OverallNB.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(OverallNB, file)\n",
    "\n",
    "pkl_filename = \"OverallSGD.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(OverallSGD, file)\n",
    "\n",
    "pkl_filename = \"OverallADA.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(OverallADA, file)\n",
    "\n",
    "pkl_filename = \"OverallRF.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(OverallRF, file)\n",
    "\n",
    "pkl_filename = \"OverallXGB.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(OverallXGB, file)\n",
    "\n",
    "    # Load from file\n",
    "pkl_filename = \"OverallNB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    OverallNB = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"OverallSGD.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    OverallSGD = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"OverallADA.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    OverallADA = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"OverallRF.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    OverallRF = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"OverallXGB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    OverallXGB = pickle.load(file)\n",
    "\n",
    "predictions_NB = OverallNB.predict(Test_X_overall)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****NB Report****\")\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(Test_Y_overall, predictions_NB))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_overall, predictions_NB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_overall, predictions_NB)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SGD = OverallSGD.predict(Test_X_overall)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****SGD Report****\")\n",
    "print(\"SGD Accuracy:\",metrics.accuracy_score(Test_Y_overall, predictions_SGD))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_overall, predictions_SGD))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_overall, predictions_SGD))\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_ADA = OverallADA.predict(Test_X_overall)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****ADABoost Report****\")\n",
    "print(\"AdaBoostClassifier Accuracy:\",metrics.accuracy_score(Test_Y_overall, predictions_ADA))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_overall, predictions_ADA))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_overall, predictions_ADA) )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_RF = OverallRF.predict(Test_X_overall)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****RF Report****\")\n",
    "print(\"RandomForest Accuracy:\",metrics.accuracy_score(Test_Y_overall, predictions_RF))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_overall, predictions_RF))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_overall, predictions_RF)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_XGB = OverallXGB.predict(Test_X_overall)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****XGB Report****\")\n",
    "print(\"XGBoost Accuracy:\",metrics.accuracy_score(Test_Y_overall, predictions_XGB))\n",
    "print('\\nClasification report:\\n', classification_report(Test_Y_overall, predictions_XGB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(Test_Y_overall, predictions_XGB)  )\n",
    "\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "makeROC([OverallNB, OverallXGB, OverallRF, OverallADA, OverallSGD],\"TFIDF extract Real Vs Fake Performance\", Test_X_overall, Test_Y_overall)"
   ]
  },
  {
   "source": [
    "# Test on Entertainment Domain"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Combine data into a DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBDIR = \"entertainment\"\n",
    "FILENAME = [\"real/\", \"fake/\"]\n",
    "\n",
    "file_directory = 'data/SampleText'\n",
    "filename_pattern = '.+\\.txt'\n",
    "\n",
    "regex_pattern = \"[a-zA-Z'_]+\"\n",
    "\n",
    "text = []\n",
    "for file in FILENAME: \n",
    "    file_dir = DIR + SUBDIR + file\n",
    "    entries = os.listdir(file_dir)\n",
    "    for f in entries:\n",
    "        with open(file_dir + f, 'r', encoding=\"utf8\") as file: \n",
    "            lines = file.readlines()\n",
    "            # cleanedLines = [[w for w in l if re.search(regex_pattern,w)] for l in lines]\n",
    "            joinedLines = ' '.join(lines)\n",
    "            joinedLines = joinedLines.strip(\"\\n\")\n",
    "            text.append(joinedLines)\n",
    "\n",
    "label  = [1 for i in range(50)] + [0 for i in range(50)] \n",
    "title  = [\"Entertainment\" for i in range(100)]\n",
    "index  = [i for i in range(100)]\n",
    "df = pd.DataFrame({\"index\":index, \"title\":title, \"text\":text, \"label\":label})\n",
    "\n",
    "df.to_excel(DIR + SUBDIR +\"entertainment_text.xlsx\")"
   ]
  },
  {
   "source": [
    "## Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherdf = pd.read_excel('sample_data/entertainment_text.xlsx')\n",
    "otherdf['text'] = otherdf.apply(lambda x: preprocessG(x['text']), axis=1)\n",
    "otherdf.to_excel(DIR + SUBDIR + 'entertainment_text_clean.xlsx', index = False, header=True)\n",
    "entertainmentdf = pd.read_excel(DIR + SUBDIR + 'entertainment_text_clean.xlsx')\n"
   ]
  },
  {
   "source": [
    "## Topic Modelling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_e = entertainmentdf['text']\n",
    "\n",
    "entertainment_docs = [[w for w in new.split()] for new in news ]\n",
    "entertainment_vecs = docs2vecs(entertainment_docs, news_dictionary)\n",
    "\n",
    "classifier_saved = open(\"topicModel14.pickle\", \"rb\") #binary read\n",
    "classifier_load = pickle.load(classifier_saved)\n",
    "classifier_saved.close()\n",
    "df_topic_sents_keywords_e = format_topics_sentences(ldamodel=classifier_load, corpus=entertainment_vecs, data=entertainment_docs)\n",
    "\n",
    "# Format\n",
    "# df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_topic_sents_keywords_e.columns = ['Topic 0','Topic 1','Topic 2','Topic 3','Topic 4','Topic 5', 'Topic 6','Topic 7','Topic 8','Topic 9','Topic 10','Topic 11','Topic 12','Topic 13','Text']\n",
    "\n",
    "# Show\n",
    "# print (df_topic_sents_keywords_e.head(10))\n",
    "df_topic_sents_keywords_e.to_excel('entertainment_text_topic_dist.xlsx')\n"
   ]
  },
  {
   "source": [
    "## POS Tag + Emotions/Sentiment Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entertainmentdf_emo = generate_emotions(entertainmentdf)\n",
    "entertainmentdf_emo.drop_duplicates(inplace=True)\n",
    "entertainmentdf_emo.to_excel(DIR + SUBDIR + 'emotion_analysis_final_entertainment.xlsx')\n",
    "\n",
    "emp_df_e = pd.read_excel(DIR + SUBDIR + 'emotion_analysis_final_entertainment.xlsx')\n",
    "\n",
    "emo_pos_df_e = generate_pos_tag_dist(emp_df_e)\n",
    "emp_df_e = emp_df_e.reset_index()\n",
    "emp_df_e = emp_df_e[emp_df_e.columns.drop(list(emp_df_e.filter(regex='index')))]\n",
    "emp_df_e = emp_df_e.rename(columns={emp_df_e.columns[0]: 'index'})\n",
    "comb_emo_pos_dist_e =  emp_df_e.merge(emo_pos_df_e, left_on='index', right_on='index')\n",
    "\n",
    "emo_pos_dist_pscore_e = vader_score_generation(comb_emo_pos_dist_e)\n",
    "emo_pos_dist_pscore_e.to_excel(DIR + SUBDIR + 'emo_pos_dist_pscore_entertainment.xlsx')\n",
    "\n",
    "# Generating of Pos Grouping Features \n",
    "emotional_df_stack_e = pd.read_excel(DIR + SUBDIR + 'emo_pos_dist_pscore_entertainment.xlsx')\n",
    "del emotional_df_stack_e['compound']\n",
    "\n",
    "emotional_df_stack_groupped_pos_e, pos_tags_e = group_pos_features(emotional_df_stack_e)\n",
    "emotional_df_stack_groupped_pos_e.drop(columns=pos_tags_e, inplace=True)\n",
    "emotional_df_stack_groupped_pos_e = emotional_df_stack_groupped_pos_e.loc[:, (emotional_df_stack_groupped_pos_e != 0).any(axis=0)]\n",
    "emotional_df_stack_groupped_pos_e.to_excel('sample_data/pos_groupings_vader_emotion.xlsx')\n"
   ]
  },
  {
   "source": [
    "## Entity Recognition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fake News\n",
    "df1fake_e = otherdf[otherdf['label'] == 0]                                 # 1) Get fake news article dataframe\n",
    "index_list_e = df1fake_e.index.tolist()                                 # 2) Get index of fake dataframe\n",
    "# fakeEntityDic = getEntityDic(df1fake)                               # 3) Get sorted dict of {fake entities : count}\n",
    "# fakeTop = getTopEntityDic(fakeEntityDic, 10)                        # 4) Get dic of {entitiy type : [sorted list of top 10 entities]}\n",
    "df1_fakeEntities_e = addEntitiesToDataframe2(df1fake_e)                 # 5) Get DF with all entities, entity type count per article\n",
    "\n",
    "# Real News\n",
    "df1true_e = otherdf[otherdf['label'] == 1]                                 # 1) Get real news article dataframe\n",
    "index_list_e = df1true_e.index.tolist()                                 # 2) Get index of real dataframe\n",
    "# trueEntityDic = getEntityDic(df1true)                               # 3) Get sorted dict of {real entities : count}\n",
    "# trueTop = getTopEntityDic(trueEntityDic, 10)                        # 4) Get dic of {entitiy type : [sorted list of top 10 entities]}\n",
    "df1_trueEntities_e = addEntitiesToDataframe2(df1true_e)                 # 5) Get DF of entities, entity count per article\n",
    "\n",
    "# Combining Real and Fake News Dataframes\n",
    "finalEntitydf_e = pd.concat([df1_trueEntities_e, df1_fakeEntities_e])     # Union fake & real dataframes\n",
    "finalEntitydf_e.sort_index(ascending=True, inplace=True)              # Re-index them to original state\n",
    "\n",
    "# # Attaching Top Entities as Column Headers to Main Dataframe                   \n",
    "# finalEntitydf_e, store_e = attachTopEntities(finalEntitydf_e, fakeTop_e, trueTop_e)       \n",
    "\n",
    "# # Get Final DF with Top Entity counts\n",
    "# mainEntitydf_e = getFinalEntityDF(finalEntitydf_e, store_e)\n",
    "# mainEntitydf_e.head(3)\n",
    "\n",
    "del finalEntitydf_e['person entities']\n",
    "del finalEntitydf_e['organisation entities']\n",
    "del finalEntitydf_e['location entities']\n",
    "del emotional_df_stack_groupped_pos_e['Unnamed: 0']\n",
    "\n",
    "horizontal_stack_e = emotional_df_stack_groupped_pos_e.merge(finalEntitydf_e, how='left', on='index')\n",
    "horizontal_stack_e = horizontal_stack_e.loc[:,~horizontal_stack_e.columns.duplicated()]\n",
    "del horizontal_stack_e['label']\n",
    "del horizontal_stack_e['label_x']\n",
    "del horizontal_stack_e['title_y']\n",
    "del horizontal_stack_e['text_y']\n",
    "del horizontal_stack_e[',']\n",
    "del horizontal_stack_e['.']\n",
    "\n",
    "horizontal_stack_e.to_excel('final_feature_engineered_entertainment.xlsx')"
   ]
  },
  {
   "source": [
    "## Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Sentiment dataset\n",
    "dfemotionEntertainment = pd.read_excel(\"sample_data/Entertainment text + Sentiment Data.xlsx\")\n",
    "dfEntertainment = dfemotionEntertainment['text_x']\n",
    "dfEntertainmentY = dfemotionEntertainment['label_y']\n",
    "dfemotionEntertainment = dfemotionEntertainment.drop(['text_x','title_x','Unnamed: 0','index','label_y',':','(',')','group_c','PRP','NNP','group_m'], axis=1)\n",
    "\n",
    "#Split text set to 20k rows from original extract\n",
    "Train_X_Entertainment, Test_X_Entertainment, Train_Y_Entertainment, Test_Y_Entertainment = model_selection.train_test_split(df['text'],df['label'],train_size= 0.45, stratify=df['label'], random_state=0)\n",
    "\n",
    "#TFIDF Vectorize New Sample Set with trained vectorizer from old domain extract\n",
    "fulllist = []\n",
    "for i in Train_X_Entertainment:\n",
    "    fulllist.append(i)\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(fulllist)\n",
    "AlternateTrain_X_Tfidf = Tfidf_vect.transform(dfEntertainment)\n",
    "\n",
    "#Convert to dataframe\n",
    "Entertainment_Train_X_df = pd.DataFrame(AlternateTrain_X_Tfidf.toarray(), columns=Tfidf_vect.get_feature_names())\n",
    "\n",
    "#Create Topic Entertainment DF\n",
    "dftopicEntertainment = pd.read_excel(\"sample_data/topic_distribution_14_entertainment.xlsx\")\n",
    "dftopicEntertainment = dftopicEntertainment.drop(['Unnamed: 0','Text'], axis=1)\n",
    "dftopicEntertainment = pd.concat([dftopicEntertainment, Entertainment_Train_X_df], axis=1)\n",
    "\n",
    "#Create Overall Entertainment Dataset\n",
    "Entertainmentdftopiccleaned = dftopicEntertainment.drop(['neg'], axis = 1)\n",
    "dfoverallEntertainment = pd.concat([Entertainmentdftopiccleaned, dfemotionEntertainment], axis=1)"
   ]
  },
  {
   "source": [
    "### Base Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "pkl_filename = \"BaseExtractTFIDFNB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TFIDFNB = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseExtractTFIDFSGD.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TFIDFSGD = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseExtractTFIDFADA.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TFIDFADA = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseExtractTFIDFRF.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TFIDFRF = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"BaseExtractTFIDFXGB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TFIDFXGB = pickle.load(file)\n",
    "\n",
    "    # replace ngram_range = (1,2) for bigram\n",
    "predictions_NB = TFIDFNB.predict(Entertainment_Train_X_df)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****NB Report****\")\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_NB))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_NB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_NB)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SGD = TFIDFSGD.predict(Entertainment_Train_X_df)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****SGD Report****\")\n",
    "print(\"SGD Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_SGD))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_SGD))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_SGD))\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_ADA = TFIDFADA.predict(Entertainment_Train_X_df)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****ADABoost Report****\")\n",
    "print(\"AdaBoostClassifier Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_ADA))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_ADA))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_ADA) )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_RF = TFIDFRF.predict(Entertainment_Train_X_df)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****RF Report****\")\n",
    "print(\"RandomForest Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_RF))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_RF))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_RF)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_XGB = TFIDFXGB.predict(Entertainment_Train_X_df)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****XGB Report****\")\n",
    "print(\"XGBoost Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_XGB))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_XGB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_XGB)  )\n",
    "\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "makeROC([TFIDFNB, TFIDFXGB, TFIDFRF, TFIDFADA, TFIDFSGD],\"TFIDF extract Real Vs Fake Performance\",Entertainment_Train_X_df, dfEntertainmentY)"
   ]
  },
  {
   "source": [
    "### Base + Topic Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "pkl_filename = \"TopicTFIDFNB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TopicNB = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"TopicTFIDFSGD.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TopicSGD = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"TopicTFIDFADA.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TopicADA = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"TopicTFIDFRF.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TopicRF = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"TopicTFIDFXGB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    TopicXGB = pickle.load(file)\n",
    "\n",
    "# replace ngram_range = (1,2) for bigram\n",
    "predictions_NB = TopicNB.predict(dftopicEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****NB Report****\")\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_NB))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_NB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_NB)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SGD = TopicSGD.predict(dftopicEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****SGD Report****\")\n",
    "print(\"SGD Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_SGD))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_SGD))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_SGD))\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_ADA = TopicADA.predict(dftopicEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****ADABoost Report****\")\n",
    "print(\"AdaBoostClassifier Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_ADA))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_ADA))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_ADA) )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_RF = TopicRF.predict(dftopicEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****RF Report****\")\n",
    "print(\"RandomForest Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_RF))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_RF))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_RF)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_XGB = TopicXGB.predict(dftopicEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****XGB Report****\")\n",
    "print(\"XGBoost Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_XGB))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_XGB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_XGB)  )\n",
    "\n",
    "makeROC([TopicNB, TopicXGB, TopicRF, TopicADA, TopicSGD],\"TFIDF + Topic probabilities Real Vs Fake Performance\",dftopicEntertainment, dfEntertainmentY)"
   ]
  },
  {
   "source": [
    "### Generic Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "pkl_filename = \"EmotionNB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionNB = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"EmotionSGD.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionSGD = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"EmotionADA.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionADA = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"EmotionRF.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionRF = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"EmotionXGB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    EmotionXGB = pickle.load(file)\n",
    "\n",
    "# replace ngram_range = (1,2) for bigram\n",
    "predictions_NB = EmotionNB.predict(dfemotionEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****NB Report****\")\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_NB))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_NB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_NB)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SGD = EmotionSGD.predict(dfemotionEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****SGD Report****\")\n",
    "print(\"SGD Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_SGD))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_SGD))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_SGD))\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_ADA = EmotionADA.predict(dfemotionEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****ADABoost Report****\")\n",
    "print(\"AdaBoostClassifier Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_ADA))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_ADA))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_ADA) )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_RF = EmotionRF.predict(dfemotionEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****RF Report****\")\n",
    "print(\"RandomForest Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_RF))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_RF))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_RF)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_XGB = EmotionXGB.predict(dfemotionEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****XGB Report****\")\n",
    "print(\"XGBoost Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_XGB))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_XGB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_XGB)  )\n",
    "\n",
    "makeROC([ EmotionNB, EmotionXGB, EmotionRF, EmotionADA, EmotionSGD],\"Sentiment, POS, and Entity Real Vs Fake Performance\", dfemotionEntertainment, dfEntertainmentY)\n"
   ]
  },
  {
   "source": [
    "### Overall Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "pkl_filename = \"OverallNB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    OverallNB = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"OverallSGD.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    OverallSGD = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"OverallADA.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    OverallADA = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"OverallRF.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    OverallRF = pickle.load(file)\n",
    "\n",
    "# Load from file\n",
    "pkl_filename = \"OverallXGB.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    OverallXGB = pickle.load(file)\n",
    "\n",
    "predictions_NB = OverallNB.predict(dfoverallEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****NB Report****\")\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_NB))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_NB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_NB)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SGD = OverallSGD.predict(dfoverallEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****SGD Report****\")\n",
    "print(\"SGD Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_SGD))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_SGD))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_SGD))\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_ADA = OverallADA.predict(dfoverallEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****ADABoost Report****\")\n",
    "print(\"AdaBoostClassifier Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_ADA))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_ADA))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_ADA) )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_RF = OverallRF.predict(dfoverallEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****RF Report****\")\n",
    "print(\"RandomForest Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_RF))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_RF))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_RF)  )\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "\n",
    "predictions_XGB = OverallXGB.predict(dfoverallEntertainment)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"****XGB Report****\")\n",
    "print(\"XGBoost Accuracy:\",metrics.accuracy_score(dfEntertainmentY, predictions_XGB))\n",
    "print('\\nClasification report:\\n', classification_report(dfEntertainmentY, predictions_XGB))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(dfEntertainmentY, predictions_XGB)  )\n",
    "\n",
    "print()\n",
    "print(\"*\"*36)\n",
    "\n",
    "makeROC([OverallNB, OverallXGB, OverallRF, OverallADA, OverallSGD],\"TFIDF extract Real Vs Fake Performance\",dfoverallEntertainment, dfEntertainmentY)"
   ]
  }
 ]
}