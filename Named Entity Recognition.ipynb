{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwKJgzDnFtKY"
   },
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8twkFUl1AyU",
    "outputId": "014919c3-ae8c-4089-de51-b0f638e53008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from wordcloud) (1.19.5)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "#For Text Cleaning\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#For EDA\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#For text vectorizing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import random\n",
    "\n",
    "#For naives bayes DF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix   \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Emotion Analysis \n",
    "# import text2emotion as te\n",
    "\n",
    "# pos tagging \n",
    "from collections import Counter\n",
    "\n",
    "# ploting \n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# VADER generation \n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tjy0fTX3zOiC",
    "outputId": "f701f748-83c0-45ba-a88d-40ca67120fca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfrLnIfZFyJA"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Azz4-juw0QSE",
    "outputId": "a9e2f02b-3831-46d2-af80-c1aad4f3d5d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senate bill would count munis toward bank liqu...</td>\n",
       "      <td>Bonds sold by U.S. states, cities, schools and...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>8003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany to reach out to Trump government to ke...</td>\n",
       "      <td>Germany wants to reach out to the future U.S. ...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>6254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkey to review 11,480 cases linked to app us...</td>\n",
       "      <td>Turkish prosecutors said on Wednesday they wil...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>11307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  ...  index\n",
       "0  Senate bill would count munis toward bank liqu...  ...   8003\n",
       "1  Germany to reach out to Trump government to ke...  ...   6254\n",
       "2  Turkey to review 11,480 cases linked to app us...  ...  11307\n",
       "\n",
       "[3 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/content/drive/MyDrive/CompiledNewsDataIndexed.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YRSW1D8GHQp"
   },
   "source": [
    "## Fake News Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jsbuNoE80Qs0"
   },
   "outputs": [],
   "source": [
    "# Get fake news article dataframe\n",
    "df1fake = df[df['label'] == 'FAKE']\n",
    "\n",
    "# Get index of fake dataframe\n",
    "index_list = df1fake.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LShDvkomBhTo"
   },
   "outputs": [],
   "source": [
    "fakeEntityDic = getEntityDic(df1fake)\n",
    "with open('fake_entity_dic.json', 'w') as fp:\n",
    "    json.dump(fakeEntityDic, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HF4-aWpu5cL-",
    "outputId": "5ec6118d-0895-4fdc-c028-6601a1881901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON\n",
      "----------------\n",
      "trump                                    :17691\n",
      "clinton                                  :5209\n",
      "donald trump                             :4867\n",
      "obama                                    :4179\n",
      "hillary clinton                          :2897\n",
      "hillary                                  :2476\n",
      "donald                                   :1340\n",
      "fox news                                 :779\n",
      "barack obama                             :756\n",
      "twitter                                  :726\n",
      "\n",
      "ORGANIZATION\n",
      "----------------\n",
      "republican                               :2829\n",
      "fbi                                      :2651\n",
      "trump                                    :1939\n",
      "gop                                      :1740\n",
      "congress                                 :1449\n",
      "cnn                                      :1370\n",
      "video                                    :1296\n",
      "democratic                               :1212\n",
      "senate                                   :1186\n",
      "us                                       :1108\n",
      "\n",
      "GPE\n",
      "----------------\n",
      "trump                                    :3798\n",
      "america                                  :3692\n",
      "american                                 :3469\n",
      "russia                                   :2669\n",
      "united states                            :2575\n",
      "russian                                  :1985\n",
      "washington                               :1219\n",
      "new york                                 :884\n",
      "iran                                     :751\n",
      "americans                                :744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trt = getTopEntityDic(fakeEntityDic, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nIXQAVvf-SvT",
    "outputId": "7637b980-fb20-4aaf-d0cc-58ea4bfb519a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion progress: 9821 of 9821 articles"
     ]
    }
   ],
   "source": [
    "df1_fakeEntities = addEntitiesToDataframe2(df1fake.copy(), trt)\n",
    "df1_fakeEntities.to_csv(\"df1_fakeEntities_30.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "M53PZDSVBKrc",
    "outputId": "ca311eae-e871-4734-d4b5-46f218304d90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>person entities</th>\n",
       "      <th>organisation entities</th>\n",
       "      <th>location entities</th>\n",
       "      <th>person entity count</th>\n",
       "      <th>organisation entity count</th>\n",
       "      <th>location entity count</th>\n",
       "      <th>(GPE)germany</th>\n",
       "      <th>(GPE)south</th>\n",
       "      <th>(GPE)turkey</th>\n",
       "      <th>(GPE)ankara</th>\n",
       "      <th>(GPE)senate</th>\n",
       "      <th>(GPE)muni</th>\n",
       "      <th>(GPE)new york democrat</th>\n",
       "      <th>(GPE)schumer</th>\n",
       "      <th>(GPE)washington</th>\n",
       "      <th>(GPE)merkel</th>\n",
       "      <th>(ORGANIZATION)germany</th>\n",
       "      <th>(ORGANIZATION)south</th>\n",
       "      <th>(ORGANIZATION)bylock</th>\n",
       "      <th>(ORGANIZATION)turkey</th>\n",
       "      <th>(ORGANIZATION)ankara</th>\n",
       "      <th>(ORGANIZATION)senate</th>\n",
       "      <th>(ORGANIZATION)nast</th>\n",
       "      <th>(ORGANIZATION)greenpeace africa</th>\n",
       "      <th>(ORGANIZATION)muni</th>\n",
       "      <th>(ORGANIZATION)new york democrat</th>\n",
       "      <th>(PERSON)germany</th>\n",
       "      <th>(PERSON)south</th>\n",
       "      <th>(PERSON)bylock</th>\n",
       "      <th>(PERSON)turkey</th>\n",
       "      <th>(PERSON)ankara</th>\n",
       "      <th>(PERSON)senate</th>\n",
       "      <th>(PERSON)nast</th>\n",
       "      <th>(PERSON)greenpeace africa</th>\n",
       "      <th>(PERSON)africa</th>\n",
       "      <th>(PERSON)muni</th>\n",
       "      <th>(PERSON)trump</th>\n",
       "      <th>(PERSON)gingrich</th>\n",
       "      <th>(PERSON)clinton</th>\n",
       "      <th>(PERSON)kelly</th>\n",
       "      <th>(PERSON)schultz</th>\n",
       "      <th>(PERSON)donald trump</th>\n",
       "      <th>(PERSON)jeh johnson</th>\n",
       "      <th>(PERSON)corey lewandowski</th>\n",
       "      <th>(PERSON)bill clinton</th>\n",
       "      <th>(PERSON)johnson</th>\n",
       "      <th>(ORGANIZATION)trump</th>\n",
       "      <th>(ORGANIZATION)gingrich</th>\n",
       "      <th>(ORGANIZATION)clinton</th>\n",
       "      <th>(ORGANIZATION)kelly</th>\n",
       "      <th>(ORGANIZATION)dnc</th>\n",
       "      <th>(ORGANIZATION)republican</th>\n",
       "      <th>(ORGANIZATION)schultz</th>\n",
       "      <th>(ORGANIZATION)donald trump</th>\n",
       "      <th>(ORGANIZATION)jeh johnson</th>\n",
       "      <th>(ORGANIZATION)corey lewandowski</th>\n",
       "      <th>(GPE)gingrich</th>\n",
       "      <th>(GPE)clinton</th>\n",
       "      <th>(GPE)dnc</th>\n",
       "      <th>(GPE)republican</th>\n",
       "      <th>(GPE)schultz</th>\n",
       "      <th>(GPE)donald trump</th>\n",
       "      <th>(GPE)jeh johnson</th>\n",
       "      <th>(GPE)corey lewandowski</th>\n",
       "      <th>(GPE)bill clinton</th>\n",
       "      <th>(GPE)dhs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senate bill would count munis toward bank liqu...</td>\n",
       "      <td>Bonds sold by U.S. states, cities, schools and...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>8003</td>\n",
       "      <td>{'chuck schumer': 1, 'mike rounds': 1, 'dakota...</td>\n",
       "      <td>{'hqlas': 1, 'senators mark warner': 1, 'virgi...</td>\n",
       "      <td>{'senate': 1, 'muni': 1, 'new york democrat': ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany to reach out to Trump government to ke...</td>\n",
       "      <td>Germany wants to reach out to the future U.S. ...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>6254</td>\n",
       "      <td>{'donald trump': 1, 'chancellor angela merkel'...</td>\n",
       "      <td>{'nato': 1}</td>\n",
       "      <td>{'germany': 5, 'merkel': 1, 'united states': 1}</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkey to review 11,480 cases linked to app us...</td>\n",
       "      <td>Turkish prosecutors said on Wednesday they wil...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>11307</td>\n",
       "      <td>{'yuksel kocaman': 1}</td>\n",
       "      <td>{'bylock': 4, 'fethullah gulen': 1}</td>\n",
       "      <td>{'turkish': 1, 'turkey': 3, 'ankara': 2, 'gule...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 things to watch in tonight’s GOP debate</td>\n",
       "      <td>Killing Obama administration rules, dismantlin...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>2688</td>\n",
       "      <td>{'obama': 1, 'obamacare': 1}</td>\n",
       "      <td>{'gop': 1}</td>\n",
       "      <td>{}</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Activists to appeal new South African nuclear ...</td>\n",
       "      <td>- Greenpeace Africa and other NGOs intend to a...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>14941</td>\n",
       "      <td>{'cape town': 1, 'eskom': 1, 'koeberg': 1, 'af...</td>\n",
       "      <td>{'greenpeace africa': 2, 'ngos': 1, 'edf': 1, ...</td>\n",
       "      <td>{'south africa': 1, 'south': 3, 'pretoria': 1,...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DEBBIE WASSERMAN SCHULTZ Accuses Obama’s DHS D...</td>\n",
       "      <td>Rep. Debbie Wasserman Schultz dropped a big bo...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>10557</td>\n",
       "      <td>{'debbie': 1, 'wasserman schultz': 1, 'jeh joh...</td>\n",
       "      <td>{'cnn': 2, 'dnc': 5, 'fbi': 2, 'dhs': 3, 'wiki...</td>\n",
       "      <td>{'whoa': 1, 'russians': 1}</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Trump Gets P*SSED As TODAY Hosts Slam His ‘Ly...</td>\n",
       "      <td>A smart presidential candidate would immediate...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>7206</td>\n",
       "      <td>{'donald trump': 1, 'corey lewandowski': 3, 't...</td>\n",
       "      <td>{'hosts.host savannah guthrie': 1, 'republican...</td>\n",
       "      <td>{'savannah': 1, 'united states': 1, 'american'...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>get ready for a likely market crash after elec...</td>\n",
       "      <td>by gordon duff senior editor on october   radi...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>1830</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Megyn Kelly Called Trump A ‘Predator’; What N...</td>\n",
       "      <td>It s Fox News, but that doesn t mean that ever...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>4044</td>\n",
       "      <td>{'fox news': 1, 'donald trump': 1, 'anchor': 1...</td>\n",
       "      <td>{'trump': 1, 'republican': 1, 'house': 1, 'con...</td>\n",
       "      <td>{'kelly': 1, 'trump': 1, 'illinois': 1}</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>This Map Explains GOP Panic: Dems Headed For ...</td>\n",
       "      <td>The Republican Party is panicking over Donald ...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>7282</td>\n",
       "      <td>{'donald trump': 2, 'trump': 4, 'hillary clint...</td>\n",
       "      <td>{'republican party': 2, 'nate silver': 2, 'fiv...</td>\n",
       "      <td>{'political': 1, 'bloomberg': 1, 'quinnipiac':...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  ... (GPE)dhs\n",
       "0   Senate bill would count munis toward bank liqu...  ...        0\n",
       "1   Germany to reach out to Trump government to ke...  ...        0\n",
       "2   Turkey to review 11,480 cases linked to app us...  ...        0\n",
       "3           5 things to watch in tonight’s GOP debate  ...        0\n",
       "4   Activists to appeal new South African nuclear ...  ...        0\n",
       "5   DEBBIE WASSERMAN SCHULTZ Accuses Obama’s DHS D...  ...        0\n",
       "10   Trump Gets P*SSED As TODAY Hosts Slam His ‘Ly...  ...        0\n",
       "13  get ready for a likely market crash after elec...  ...        0\n",
       "15   Megyn Kelly Called Trump A ‘Predator’; What N...  ...        0\n",
       "18   This Map Explains GOP Panic: Dems Headed For ...  ...        0\n",
       "\n",
       "[10 rows x 70 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalEntitydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "id": "_Tx1MKg2dKuA",
    "outputId": "379b6b1a-3ba2-49a7-81fe-4af5dea73bd0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>person entities</th>\n",
       "      <th>organisation entities</th>\n",
       "      <th>location entities</th>\n",
       "      <th>person entity count</th>\n",
       "      <th>organisation entity count</th>\n",
       "      <th>location entity count</th>\n",
       "      <th>(True,G) united states</th>\n",
       "      <th>(True,G) u.s</th>\n",
       "      <th>(True,G) russia</th>\n",
       "      <th>(True,G) china</th>\n",
       "      <th>(True,G) iran</th>\n",
       "      <th>(True,G) trump</th>\n",
       "      <th>(True,G) washington</th>\n",
       "      <th>(True,G) russian</th>\n",
       "      <th>(True,G) north korea</th>\n",
       "      <th>(True,G) american</th>\n",
       "      <th>(True,O) republican</th>\n",
       "      <th>(True,O) united states</th>\n",
       "      <th>(True,O) u.s</th>\n",
       "      <th>(True,O) senate</th>\n",
       "      <th>(True,O) house</th>\n",
       "      <th>(True,O) russia</th>\n",
       "      <th>(True,O) china</th>\n",
       "      <th>(True,O) congress</th>\n",
       "      <th>(True,O) democratic</th>\n",
       "      <th>(True,O) iran</th>\n",
       "      <th>(True,P) trump</th>\n",
       "      <th>(True,P) clinton</th>\n",
       "      <th>(True,P) republican</th>\n",
       "      <th>(True,P) united states</th>\n",
       "      <th>(True,P) u.s</th>\n",
       "      <th>(True,P) donald trump</th>\n",
       "      <th>(True,P) senate</th>\n",
       "      <th>(True,P) house</th>\n",
       "      <th>(True,P) russia</th>\n",
       "      <th>(True,P) china</th>\n",
       "      <th>(Fake,P) trump</th>\n",
       "      <th>(Fake,P) clinton</th>\n",
       "      <th>(Fake,P) donald trump</th>\n",
       "      <th>(Fake,P) obama</th>\n",
       "      <th>(Fake,P) hillary clinton</th>\n",
       "      <th>(Fake,P) hillary</th>\n",
       "      <th>(Fake,P) donald</th>\n",
       "      <th>(Fake,P) fox news</th>\n",
       "      <th>(Fake,P) barack obama</th>\n",
       "      <th>(Fake,P) twitter</th>\n",
       "      <th>(Fake,O) clinton</th>\n",
       "      <th>(Fake,O) donald trump</th>\n",
       "      <th>(Fake,O) obama</th>\n",
       "      <th>(Fake,O) hillary clinton</th>\n",
       "      <th>(Fake,O) republican</th>\n",
       "      <th>(Fake,O) fbi</th>\n",
       "      <th>(Fake,O) hillary</th>\n",
       "      <th>(Fake,O) trump</th>\n",
       "      <th>(Fake,O) gop</th>\n",
       "      <th>(Fake,O) congress</th>\n",
       "      <th>(Fake,G) clinton</th>\n",
       "      <th>(Fake,G) donald trump</th>\n",
       "      <th>(Fake,G) obama</th>\n",
       "      <th>(Fake,G) trump</th>\n",
       "      <th>(Fake,G) america</th>\n",
       "      <th>(Fake,G) american</th>\n",
       "      <th>(Fake,G) hillary clinton</th>\n",
       "      <th>(Fake,G) republican</th>\n",
       "      <th>(Fake,G) russia</th>\n",
       "      <th>(Fake,G) fbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senate bill would count munis toward bank liqu...</td>\n",
       "      <td>Bonds sold by U.S. states, cities, schools and...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>8003</td>\n",
       "      <td>{'chuck schumer': 1, 'mike rounds': 1, 'dakota...</td>\n",
       "      <td>{'hqlas': 1, 'senators mark warner': 1, 'virgi...</td>\n",
       "      <td>{'senate': 1, 'muni': 1, 'new york democrat': ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany to reach out to Trump government to ke...</td>\n",
       "      <td>Germany wants to reach out to the future U.S. ...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>6254</td>\n",
       "      <td>{'donald trump': 1, 'chancellor angela merkel'...</td>\n",
       "      <td>{'nato': 1}</td>\n",
       "      <td>{'germany': 5, 'merkel': 1, 'united states': 1}</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkey to review 11,480 cases linked to app us...</td>\n",
       "      <td>Turkish prosecutors said on Wednesday they wil...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>11307</td>\n",
       "      <td>{'yuksel kocaman': 1}</td>\n",
       "      <td>{'bylock': 4, 'fethullah gulen': 1}</td>\n",
       "      <td>{'turkish': 1, 'turkey': 3, 'ankara': 2, 'gule...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 things to watch in tonight’s GOP debate</td>\n",
       "      <td>Killing Obama administration rules, dismantlin...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>2688</td>\n",
       "      <td>{'obama': 1, 'obamacare': 1}</td>\n",
       "      <td>{'gop': 1}</td>\n",
       "      <td>{}</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Activists to appeal new South African nuclear ...</td>\n",
       "      <td>- Greenpeace Africa and other NGOs intend to a...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>14941</td>\n",
       "      <td>{'cape town': 1, 'eskom': 1, 'koeberg': 1, 'af...</td>\n",
       "      <td>{'greenpeace africa': 2, 'ngos': 1, 'edf': 1, ...</td>\n",
       "      <td>{'south africa': 1, 'south': 3, 'pretoria': 1,...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  ... (Fake,G) fbi\n",
       "0  Senate bill would count munis toward bank liqu...  ...          0.0\n",
       "1  Germany to reach out to Trump government to ke...  ...          0.0\n",
       "2  Turkey to review 11,480 cases linked to app us...  ...          0.0\n",
       "3          5 things to watch in tonight’s GOP debate  ...          0.0\n",
       "4  Activists to appeal new South African nuclear ...  ...          0.0\n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalEntitydf = finalEntitydf[asd]\n",
    "finalEntitydf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qa37DlHQHzS9"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18zj1u3vGUwO"
   },
   "outputs": [],
   "source": [
    "def getFinalEntityDF(finalEntitydf, store):\n",
    "  total_records = finalEntitydf.shape[0]\n",
    "  for index, row in finalEntitydf.iterrows():\n",
    "    sys.stdout.write('\\rCompletion progress: ' + str(index+1) + ' of ' + str(total_records) + \" articles\")\n",
    "    sys.stdout.flush()\n",
    "    # Person Entities\n",
    "    json_string = row['person entities']\n",
    "    dicp = ast.literal_eval(json_string)\n",
    "    for x in dicp:\n",
    "      item = \"(PERSON)\" + str(x)\n",
    "      if item in store:\n",
    "        finalEntitydf.loc[index, item] = dicp[x]\n",
    "\n",
    "    # Location Entities\n",
    "    json_string = row['location entities']\n",
    "    dicp = ast.literal_eval(json_string)\n",
    "    for x in dicp:\n",
    "      item = \"(GPE)\" + str(x)\n",
    "      if item in store:\n",
    "        finalEntitydf.loc[index, item] = dicp[x]\n",
    "    \n",
    "    # GPE Entities\n",
    "    json_string = row['organisation entities']\n",
    "    dicp = ast.literal_eval(json_string)\n",
    "    for x in dicp:\n",
    "      item = \"(ORGANISATION)\" + str(x)\n",
    "      if item in store:\n",
    "        finalEntitydf.loc[index, item] = dicp[x]\n",
    "\n",
    "  return finalEntitydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zArk4CytGZDm"
   },
   "outputs": [],
   "source": [
    "def attachTopEntities(df, fakeTop, realTop):\n",
    "  store = []\n",
    "  for x in trueTop:\n",
    "    for y in trueTop[x]:\n",
    "      store.append((\"(\" + str(x) + \")\" + y))\n",
    "\n",
    "  for x in fakeTop:\n",
    "    for y in fakeTop[x]:\n",
    "      item = (\"(\" + str(x) + \")\" + y)\n",
    "      if item not in store:\n",
    "        store.append(item)\n",
    "\n",
    "  for x in store:\n",
    "    df[x] = 0\n",
    "\n",
    "  return df, store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPymYXqR8LRg"
   },
   "outputs": [],
   "source": [
    "def addEntitiesToDataframe2(df):\n",
    "\n",
    "    entity_dic = {}\n",
    "    counter = 1\n",
    "    total_records = df.shape[0]\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        entity_dic['PERSON'] = {}\n",
    "        entity_dic['ORGANIZATION'] = {}\n",
    "        entity_dic['GPE'] = {}\n",
    "        text = row['text'] + \" \"+ row['title']\n",
    "        sys.stdout.write('\\rCompletion progress: ' + str(counter) + ' of ' + str(total_records) + \" articles\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        ## Put full stop behind each sentence\n",
    "        new = []\n",
    "        if \"\\n\" in text:\n",
    "          text = text.replace(\" \\n\", \". \")\n",
    "        text_list = text.split(\". \")\n",
    "        for x in text_list:\n",
    "            new.append(x + \".\")\n",
    "\n",
    "        ## Cycle through each sentence\n",
    "        for x in new:\n",
    "            sent_tokens = word_tokenize(x)\n",
    "            tagged_sent = nltk.pos_tag(sent_tokens)\n",
    "            ne_tree = nltk.ne_chunk(tagged_sent)\n",
    "            ne_list = extract_ne_from_tree(ne_tree)\n",
    "\n",
    "            ## Insert into dictionary\n",
    "            for y in ne_list:\n",
    "                if y[0] not in entity_dic:\n",
    "                    entity_dic[y[0]] = {}\n",
    "                if y[0] in entity_dic:\n",
    "                    string = y[1].lower()\n",
    "                    if string not in entity_dic[y[0]]:\n",
    "                        entity_dic[y[0]][string] = 0\n",
    "                    if string in entity_dic[y[0]]:\n",
    "                        entity_dic[y[0]][string] += 1\n",
    "        counter += 1\n",
    "\n",
    "        # Get df index\n",
    "        ind = index_list[i]\n",
    "\n",
    "        # get summation values\n",
    "        total_p = 0\n",
    "        for x in entity_dic['PERSON']:\n",
    "          total_p += entity_dic['PERSON'][x]\n",
    "\n",
    "        total_o = 0\n",
    "        for x in entity_dic['ORGANIZATION']:\n",
    "          total_o += entity_dic['ORGANIZATION'][x]\n",
    "\n",
    "        total_g = 0\n",
    "        for x in entity_dic['GPE']:\n",
    "          total_g += entity_dic['GPE'][x]\n",
    "        \n",
    "        # insert into DF\n",
    "        df.loc[ind:ind+1, 'person entities'] = str(entity_dic['PERSON'])\n",
    "        df.loc[ind:ind+1, 'organisation entities'] = str(entity_dic['ORGANIZATION'])\n",
    "        df.loc[ind:ind+1, 'location entities'] = str(entity_dic['GPE'])\n",
    "        df.loc[ind:ind+1, 'person entity count'] = total_p\n",
    "        df.loc[ind:ind+1, 'organisation entity count'] = total_o\n",
    "        df.loc[ind:ind+1, 'location entity count'] = total_g\n",
    "        entity_dic = {}\n",
    "        i+=1\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRW81VMU2Xdz"
   },
   "outputs": [],
   "source": [
    "def addEntitiesToDataframe(df, top10):\n",
    "\n",
    "    # # create top entities columns in dataframe\n",
    "    for en in top10:\n",
    "      df[en] = 0\n",
    "\n",
    "    entity_dic = {}\n",
    "    counter = 1\n",
    "    total_records = df.shape[0]\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        entity_dic['PERSON'] = {}\n",
    "        entity_dic['ORGANIZATION'] = {}\n",
    "        entity_dic['GPE'] = {}\n",
    "        text = row['text'] + \" \"+ row['title']\n",
    "        sys.stdout.write('\\rCompletion progress: ' + str(counter) + ' of ' + str(total_records) + \" articles\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        ## Put full stop behind each sentence\n",
    "        new = []\n",
    "        if \"\\n\" in text:\n",
    "          text = text.replace(\" \\n\", \". \")\n",
    "        text_list = text.split(\". \")\n",
    "        for x in text_list:\n",
    "            new.append(x + \".\")\n",
    "\n",
    "        ## Cycle through each sentence\n",
    "        for x in new:\n",
    "            sent_tokens = word_tokenize(x)\n",
    "            tagged_sent = nltk.pos_tag(sent_tokens)\n",
    "            ne_tree = nltk.ne_chunk(tagged_sent)\n",
    "            ne_list = extract_ne_from_tree(ne_tree)\n",
    "\n",
    "            ## Insert into dictionary\n",
    "            for y in ne_list:\n",
    "                if y[0] not in entity_dic:\n",
    "                    entity_dic[y[0]] = {}\n",
    "                if y[0] in entity_dic:\n",
    "                    string = y[1].lower()\n",
    "                    if string not in entity_dic[y[0]]:\n",
    "                        entity_dic[y[0]][string] = 0\n",
    "                    if string in entity_dic[y[0]]:\n",
    "                        entity_dic[y[0]][string] += 1\n",
    "        counter += 1\n",
    "        # Get df index\n",
    "        ind = index_list[i]\n",
    "\n",
    "        # get summation values\n",
    "        total_p = 0\n",
    "        for x in entity_dic['PERSON']:\n",
    "          total_p += entity_dic['PERSON'][x]\n",
    "          if x in top10:\n",
    "            df.loc[ind:ind+1, str(x)] = int(entity_dic['PERSON'][x])\n",
    "\n",
    "        total_o = 0\n",
    "        for x in entity_dic['ORGANIZATION']:\n",
    "          total_o += entity_dic['ORGANIZATION'][x]\n",
    "          if x in top10:\n",
    "            df.loc[ind:ind+1, x] = entity_dic['ORGANIZATION'][x]\n",
    "\n",
    "        total_g = 0\n",
    "        for x in entity_dic['GPE']:\n",
    "          total_g += entity_dic['GPE'][x]\n",
    "          if x in top10:\n",
    "            df.loc[ind:ind+1, x] = entity_dic['GPE'][x]\n",
    "        \n",
    "        # insert into DF\n",
    "        df.loc[ind:ind+1, 'person entities'] = str(entity_dic['PERSON'])\n",
    "        df.loc[ind:ind+1, 'organisation entities'] = str(entity_dic['ORGANIZATION'])\n",
    "        df.loc[ind:ind+1, 'location entities'] = str(entity_dic['GPE'])\n",
    "        df.loc[ind:ind+1, 'person entity count'] = total_p\n",
    "        df.loc[ind:ind+1, 'organisation entity count'] = total_o\n",
    "        df.loc[ind:ind+1, 'location entity count'] = total_g\n",
    "        entity_dic = {}\n",
    "        i+=1\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGQQyHxv2HC2"
   },
   "outputs": [],
   "source": [
    "def extract_ne_from_tree ( tree ):\n",
    "    result = []\n",
    "    for s in tree.subtrees():\n",
    "        label = s.label()\n",
    "        if (label == 'PERSON' or label == 'ORGANIZATION' or label == 'GPE'):\n",
    "            leaves = s.leaves()\n",
    "            ne = ''\n",
    "            for l in leaves:\n",
    "                ne = ne + ' ' + l[0]\n",
    "            result.append((label, ne[1:]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ol_rUpp2Umx"
   },
   "outputs": [],
   "source": [
    "def getEntityDic(df):\n",
    "  entity_dic = {}\n",
    "  counter = 1\n",
    "  total_records = df.shape[0]\n",
    "  for index, row in df.iterrows():\n",
    "    text = row['text'] + \" \"+ row['title']\n",
    "    sys.stdout.write('\\rCompletion progress: ' + str(counter) + ' of ' + str(total_records) + \" articles\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    ## Put full stop behind each sentence\n",
    "    new = []\n",
    "    if \"\\n\" in text:\n",
    "        text = text.replace(\" \\n\", \". \")\n",
    "    text_list = text.split(\". \")\n",
    "    for x in text_list:\n",
    "        new.append(x + \".\")\n",
    "    \n",
    "    ## Cycle through each sentence\n",
    "    for x in new:\n",
    "        sent_tokens = word_tokenize(x)\n",
    "        tagged_sent = nltk.pos_tag(sent_tokens)\n",
    "        ne_tree = nltk.ne_chunk(tagged_sent)\n",
    "        ne_list = extract_ne_from_tree(ne_tree)\n",
    "        \n",
    "        ## Insert into dictionary\n",
    "        for y in ne_list:\n",
    "            if y[0] not in entity_dic:\n",
    "                entity_dic[y[0]] = {}\n",
    "            if y[0] in entity_dic:\n",
    "                string = y[1].lower()\n",
    "                if string not in entity_dic[y[0]]:\n",
    "                    entity_dic[y[0]][string] = 0\n",
    "                if string in entity_dic[y[0]]:\n",
    "                    entity_dic[y[0]][string] += 1\n",
    "    counter += 1\n",
    "  return entity_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBrhtUS82aos"
   },
   "outputs": [],
   "source": [
    "def getTopEntities(entity_dic, n):\n",
    "  new_n = 30\n",
    "  top10entities = {}\n",
    "  for x in entity_dic:\n",
    "    print(x)\n",
    "    print(\"----------------\")\n",
    "    sorted_dic = sorted(entity_dic[x], key=entity_dic[x].get, reverse=True)\n",
    "    count = 0\n",
    "    for y in sorted_dic:\n",
    "      top10entities[y] = entity_dic[x][y]\n",
    "      if count <= new_n:\n",
    "        print(y.ljust(40), \":\" + str(entity_dic[x][y]))\n",
    "      count += 1\n",
    "      if count == n:\n",
    "          break\n",
    "    print()\n",
    "\n",
    "  top10 = dict(sorted(top10entities.items(), key=lambda item: item[1], reverse = True))\n",
    "  count = 0\n",
    "  result = []\n",
    "  for x in top10:\n",
    "    count += 1\n",
    "    result.append(x)\n",
    "    if count == 50:\n",
    "      break\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRkWMZqg6SEd"
   },
   "outputs": [],
   "source": [
    "def getTopEntityDic(entity_dic, n):\n",
    "  bigstore = {}\n",
    "  top10entities = {}\n",
    "  for x in entity_dic:\n",
    "    first = str(x)[0] + \"_\"\n",
    "    bigstore[x] = []\n",
    "    print(x)\n",
    "    print(\"----------------\")\n",
    "    sorted_dic = sorted(entity_dic[x], key=entity_dic[x].get, reverse=True)\n",
    "    count = 0\n",
    "    for y in sorted_dic:\n",
    "      top10entities[y] = entity_dic[x][y]\n",
    "      print(y.ljust(40), \":\" + str(entity_dic[x][y]))\n",
    "      count += 1\n",
    "      if count == n:\n",
    "          break\n",
    "    top10 = dict(sorted(top10entities.items(), key=lambda item: item[1], reverse = True))\n",
    "    count = 0\n",
    "    result = []\n",
    "    for z in top10:\n",
    "      count += 1\n",
    "      result.append(str(z))\n",
    "      if count == n:\n",
    "        bigstore[x] = result \n",
    "        break\n",
    "    print()\n",
    "\n",
    "  \n",
    "\n",
    "  return bigstore"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "FwKJgzDnFtKY",
    "YfrLnIfZFyJA",
    "Qa37DlHQHzS9"
   ],
   "machine_shape": "hm",
   "name": "entityrec.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}